{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import words as nltk_words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer , CountVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import Pipeline , FeatureUnion\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import re\n",
    "import sys\n",
    "import string\n",
    "from time import time\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn import metrics\n",
    "DATASET_PATH = 'gender-classifier-DFE-791531.csv'\n",
    "stop = set(stopwords.words('english'))\n",
    "tokenizer = TweetTokenizer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>gender:confidence</th>\n",
       "      <th>description</th>\n",
       "      <th>link_color</th>\n",
       "      <th>name</th>\n",
       "      <th>sidebar_color</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>815719226</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>i sing my own rhythm.</td>\n",
       "      <td>08C2C2</td>\n",
       "      <td>sheezy0</td>\n",
       "      <td>FFFFFF</td>\n",
       "      <td>Robbie E Responds To Critics After Win Against...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>815719227</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>I'm the author of novels filled with family dr...</td>\n",
       "      <td>0084B4</td>\n",
       "      <td>DavdBurnett</td>\n",
       "      <td>C0DEED</td>\n",
       "      <td>â°ï¢Ö¿It felt like they were my friends and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>815719228</td>\n",
       "      <td>male</td>\n",
       "      <td>0.6625</td>\n",
       "      <td>louis whining and squealing and all</td>\n",
       "      <td>ABB8C2</td>\n",
       "      <td>lwtprettylaugh</td>\n",
       "      <td>C0DEED</td>\n",
       "      <td>i absolutely adore when louis starts the songs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>815719229</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Mobile guy.  49ers, Shazam, Google, Kleiner Pe...</td>\n",
       "      <td>0084B4</td>\n",
       "      <td>douggarland</td>\n",
       "      <td>C0DEED</td>\n",
       "      <td>Hi @JordanSpieth - Looking at the url - do you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>815719230</td>\n",
       "      <td>female</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Ricky Wilson The Best FRONTMAN/Kaiser Chiefs T...</td>\n",
       "      <td>3B94D9</td>\n",
       "      <td>WilfordGemma</td>\n",
       "      <td>0</td>\n",
       "      <td>Watching Neighbours on Sky+ catching up with t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>815719231</td>\n",
       "      <td>female</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>you don't know me.</td>\n",
       "      <td>F5ABB5</td>\n",
       "      <td>monroevicious</td>\n",
       "      <td>0</td>\n",
       "      <td>Ive seen people on the train with lamps, chair...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>815719232</td>\n",
       "      <td>brand</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>A global marketplace for images, videos and mu...</td>\n",
       "      <td>298AAE</td>\n",
       "      <td>Shutterstock</td>\n",
       "      <td>0</td>\n",
       "      <td>@BpackEngineer Thank you for your patience whi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>815719233</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>The secret of getting ahead is getting started.</td>\n",
       "      <td>0000FF</td>\n",
       "      <td>RobinMeske</td>\n",
       "      <td>C0DEED</td>\n",
       "      <td>Gala Bingo clubs bought for ×Â£241m: The UK's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>815719234</td>\n",
       "      <td>female</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Pll Fan // Crazy about MCD // Ramen is bae</td>\n",
       "      <td>9266CC</td>\n",
       "      <td>pigzilla_</td>\n",
       "      <td>0</td>\n",
       "      <td>@_Aphmau_ the pic defines all mcd fangirls/fan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>815719235</td>\n",
       "      <td>female</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Renaissance art historian, University of Notti...</td>\n",
       "      <td>9266CC</td>\n",
       "      <td>GabrieleNeher</td>\n",
       "      <td>FFFFFF</td>\n",
       "      <td>@Evielady just how lovely is the tree this yea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    _unit_id  gender  gender:confidence  \\\n",
       "0  815719226    male             1.0000   \n",
       "1  815719227    male             1.0000   \n",
       "2  815719228    male             0.6625   \n",
       "3  815719229    male             1.0000   \n",
       "4  815719230  female             1.0000   \n",
       "5  815719231  female             1.0000   \n",
       "6  815719232   brand             1.0000   \n",
       "7  815719233    male             1.0000   \n",
       "8  815719234  female             1.0000   \n",
       "9  815719235  female             1.0000   \n",
       "\n",
       "                                         description link_color  \\\n",
       "0                              i sing my own rhythm.     08C2C2   \n",
       "1  I'm the author of novels filled with family dr...     0084B4   \n",
       "2                louis whining and squealing and all     ABB8C2   \n",
       "3  Mobile guy.  49ers, Shazam, Google, Kleiner Pe...     0084B4   \n",
       "4  Ricky Wilson The Best FRONTMAN/Kaiser Chiefs T...     3B94D9   \n",
       "5                                 you don't know me.     F5ABB5   \n",
       "6  A global marketplace for images, videos and mu...     298AAE   \n",
       "7    The secret of getting ahead is getting started.     0000FF   \n",
       "8         Pll Fan // Crazy about MCD // Ramen is bae     9266CC   \n",
       "9  Renaissance art historian, University of Notti...     9266CC   \n",
       "\n",
       "             name sidebar_color  \\\n",
       "0         sheezy0        FFFFFF   \n",
       "1     DavdBurnett        C0DEED   \n",
       "2  lwtprettylaugh        C0DEED   \n",
       "3     douggarland        C0DEED   \n",
       "4    WilfordGemma             0   \n",
       "5   monroevicious             0   \n",
       "6    Shutterstock             0   \n",
       "7      RobinMeske        C0DEED   \n",
       "8       pigzilla_             0   \n",
       "9   GabrieleNeher        FFFFFF   \n",
       "\n",
       "                                                text  \n",
       "0  Robbie E Responds To Critics After Win Against...  \n",
       "1  â°ï¢Ö¿It felt like they were my friends and ...  \n",
       "2  i absolutely adore when louis starts the songs...  \n",
       "3  Hi @JordanSpieth - Looking at the url - do you...  \n",
       "4  Watching Neighbours on Sky+ catching up with t...  \n",
       "5  Ive seen people on the train with lamps, chair...  \n",
       "6  @BpackEngineer Thank you for your patience whi...  \n",
       "7  Gala Bingo clubs bought for ×Â£241m: The UK's...  \n",
       "8  @_Aphmau_ the pic defines all mcd fangirls/fan...  \n",
       "9  @Evielady just how lovely is the tree this yea...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = pd.read_csv(DATASET_PATH, encoding='utf-8',  index_col=False)#sep='\\t' header=None,\n",
    "data = pd.read_csv(DATASET_PATH, encoding='latin1',  index_col=False)#sep='\\t' header=None,\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "#filtering out some columns that we will not use:\n",
    "df.drop(['_golden','_unit_state','_trusted_judgments','_last_judgment_at','profile_yn','profile_yn:confidence',\n",
    "        'created','fav_number','gender_gold','profile_yn_gold','profileimage','retweet_count','tweet_coord',\n",
    "        'tweet_count','tweet_created','tweet_id','tweet_location','user_timezone'], axis=1,inplace=True)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fix_nan_description(description):\n",
    "    if type(description) is float:\n",
    "        return ''\n",
    "#     if description.encode('latin-1').strip() == 'nan':\n",
    "    if description.strip() == 'nan':\n",
    "        return ''\n",
    "    return description\n",
    "\n",
    "#for example:\n",
    "fix_nan_description('nan ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@ameliaearhart vs @WrightBrothers in an all exclusive fly-off'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stem(text):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    ps = PorterStemmer()\n",
    "    \n",
    "    tokens = [ps.stem(token) for token in tokens]\n",
    "    \n",
    "    return ' '.join(tokens)\n",
    "\n",
    "#for example:\n",
    "stem('regardless of context, their affection seemed non-existant')\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    stop = set(stopwords.words('english'))\n",
    "    \n",
    "    tokens = [token for token in tokens if token not in stop]\n",
    "    \n",
    "    return ' '.join(tokens)\n",
    "\n",
    "#for example:\n",
    "remove_stop_words('regardless of context, their affection seemed non-existant')\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    tokens = [token for token in tokenizer.tokenize(text) if token not in string.punctuation]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "\n",
    "def remove_url(text):    \n",
    "    return re.sub(r'https?:\\S+', '', text)\n",
    "\n",
    "#for example:\n",
    "remove_url('for more info on http, enter http://www.http.com (lo beshabat)')\n",
    "\n",
    "def remove_hashtags(text,mode):  \n",
    "    if mode == 'entire_expression':\n",
    "        return re.sub(r'#\\S+', '', text)\n",
    "    elif mode == 'only_symbol':\n",
    "        return text.replace('#','')\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "#for example:\n",
    "remove_hashtags('what did you think about the # of voters this year? use #VotersUnite to let us know.','entire_expression')\n",
    "\n",
    "remove_hashtags('#fridaymadness #nature #fun #outdoor #originalperson','only_symbol')\n",
    "\n",
    "def remove_ats(text,mode):\n",
    "    if mode == 'entire_expression':\n",
    "        return re.sub(r'@\\S+', '', text)\n",
    "    elif mode == 'only_symbol':\n",
    "        return str(text).replace('@','')\n",
    "    else:\n",
    "        return text\n",
    "    \n",
    "#for example:\n",
    "remove_ats('@ameliaearhart vs @WrightBrothers in an all exclusive fly-off','entire_expression')\n",
    "\n",
    "remove_ats('@ameliaearhart vs @WrightBrothers in an all exclusive fly-off','only_symbol')\n",
    "\n",
    "def remove_multiple_spaces(text):    \n",
    "    return re.sub(r' +', ' ', text).strip()\n",
    "\n",
    "#for example:\n",
    "remove_multiple_spaces(' @ameliaearhart       vs   @WrightBrothers in an all   exclusive fly-off ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(df, min_confidence=0.9, should_lower=False, should_stem=False, should_remove_stop_words=False, should_remove_url=False,\n",
    "                            should_remove_punctuation=False,should_remove_hashtags='none',should_remove_ats='none'):\n",
    "    \n",
    "    #basic cleaning\n",
    "    cleaner_df = df.loc[(df['gender'] != 'nan') & (df['text'] != 'nan') & (df['gender'] != 'unknown')]\n",
    "    \n",
    "    cleaner_df = cleaner_df[df['gender:confidence'] >= min_confidence]\n",
    "            \n",
    "    \n",
    "    \n",
    "    cleaner_df['description'] = [fix_nan_description(desc) for desc in cleaner_df['description']]\n",
    "\n",
    "    \n",
    "    #################################\n",
    "    #removing spam tweets:\n",
    "    cleaner_df.drop_duplicates(subset='text', keep='first', inplace=True)\n",
    "    ##################################\n",
    "    \n",
    "\n",
    "    #todo probably sucks\n",
    "    if should_lower:\n",
    "        cleaner_df['description'] = [desc.lower() for desc in cleaner_df['description']]\n",
    "        cleaner_df['text'] = [text.lower() for text in cleaner_df['text']]\n",
    "\n",
    "    #todo check this (probably sucks so leave it out)\n",
    "    if should_remove_punctuation:\n",
    "        cleaner_df['description'] = [remove_punctuation(desc) for desc in cleaner_df['description']]\n",
    "        cleaner_df['text'] = [remove_punctuation(text) for text in cleaner_df['text']]\n",
    "\n",
    "    if should_remove_url:\n",
    "        cleaner_df['description'] = [remove_url(desc) for desc in cleaner_df['description']]\n",
    "        cleaner_df['text'] = [remove_url(text) for text in cleaner_df['text']]\n",
    "        \n",
    "    if should_remove_hashtags!='none':\n",
    "        cleaner_df['description'] = [remove_hashtags(desc,should_remove_hashtags) for desc in cleaner_df['description']]\n",
    "        cleaner_df['text'] = [remove_hashtags(text,should_remove_hashtags) for text in cleaner_df['text']]\n",
    "        \n",
    "    if should_remove_ats!='none':\n",
    "        cleaner_df['description'] = [remove_ats(desc,should_remove_ats) for desc in cleaner_df['description']]\n",
    "        cleaner_df['text'] = [remove_ats(text,should_remove_ats) for text in cleaner_df['text']]\n",
    "          \n",
    "    if should_remove_stop_words:\n",
    "        cleaner_df['description'] = [remove_stop_words(desc) for desc in cleaner_df['description']]\n",
    "        cleaner_df['text'] = [remove_stop_words(text) for text in cleaner_df['text']]\n",
    "\n",
    "\n",
    "    if should_stem:\n",
    "        cleaner_df['description'] = [stem(desc) for desc in cleaner_df['description']]\n",
    "        cleaner_df['text'] = [stem(text) for text in cleaner_df['text']]\n",
    "        \n",
    "\n",
    "    #remove multiple spaces\n",
    "    cleaner_df['description'] = [remove_multiple_spaces(desc) for desc in cleaner_df['description']]\n",
    "    cleaner_df['text'] = [remove_multiple_spaces(text) for text in cleaner_df['text']]\n",
    "    cleaner_df['text_desc'] = [desc+' '+text for desc,text in zip(cleaner_df['description'],cleaner_df['text'])]\n",
    "\n",
    "    return cleaner_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records: 13165\n"
     ]
    }
   ],
   "source": [
    "clean_df = preprocess(df)\n",
    "print('Number of records: {}'.format(len(clean_df['text'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import keras.preprocessing.text as kpt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "\n",
    "#same split as with the above model\n",
    "x_train = clean_df['text_desc'][:int(0.9*len(clean_df))]\n",
    "\n",
    "gender_to_int = {'female':0,'male':1,'brand':2}\n",
    "\n",
    "y_train = list([gender_to_int[gender] for gender in clean_df['gender'][:int(0.9*len(clean_df))]]) \n",
    "y_train = keras.utils.to_categorical(y_train, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/10\n",
      "10663/10663 [==============================] - 27s 2ms/step - loss: 0.8192 - acc: 0.6072 - val_loss: 0.7202 - val_acc: 0.6616\n",
      "Epoch 2/10\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.5113 - acc: 0.7845 - val_loss: 0.7507 - val_acc: 0.6759\n",
      "Epoch 3/10\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2782 - acc: 0.8965 - val_loss: 0.9113 - val_acc: 0.6709\n",
      "Epoch 4/10\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1257 - acc: 0.9575 - val_loss: 1.1831 - val_acc: 0.6768\n",
      "Epoch 5/10\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0685 - acc: 0.9805 - val_loss: 1.3566 - val_acc: 0.6346\n",
      "Epoch 6/10\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0543 - acc: 0.9860 - val_loss: 1.4801 - val_acc: 0.6591\n",
      "Epoch 7/10\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0362 - acc: 0.9913 - val_loss: 1.5971 - val_acc: 0.6599\n",
      "Epoch 8/10\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0327 - acc: 0.9925 - val_loss: 1.6329 - val_acc: 0.6489\n",
      "Epoch 9/10\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0325 - acc: 0.9913 - val_loss: 1.6366 - val_acc: 0.6565\n",
      "Epoch 10/10\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0232 - acc: 0.9939 - val_loss: 1.7760 - val_acc: 0.6498\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2320de7bd68>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_WORDS = 10000\n",
    "\n",
    "keras_tokenizer = kpt.Tokenizer(filters='', lower=True,split = ' ',num_words=N_WORDS)#configuring the keras tokenizer to do close to nothing in terms of tokenization\n",
    "\n",
    "texts_for_keras_tokenizer = list([' '.join(tokenizer.tokenize(text)) for text in x_train]) \n",
    "\n",
    "keras_tokenizer.fit_on_texts(texts_for_keras_tokenizer)\n",
    "\n",
    "x_train = keras_tokenizer.texts_to_matrix(texts_for_keras_tokenizer, mode='binary')\n",
    "\n",
    "\n",
    "#todo optimize this\n",
    "model = Sequential()#initialize the NN\n",
    "\n",
    "#add a layer that gets N_WORDS inputs (this is the BOW representation of any tweet) and outputs 512 values ()\n",
    "model.add(Dense(512, input_shape=(N_WORDS,), activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))# this gives a distribution over all 3 genders (probability of the input's belonging to any of the gender)\n",
    "model.compile(loss='categorical_crossentropy',  optimizer='adam',  metrics=['accuracy']) \n",
    "# model.compile(loss='categorical_crossentropy',  optimizer='rmsprop',  metrics=['accuracy'])\n",
    "\n",
    "#we are using the x,y we constructed earlier,\n",
    "model.fit(x_train, y_train,  batch_size=32,  epochs=10,  verbose=1,  validation_split=0.1,  shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test = clean_df['text_desc'][int(0.9*len(clean_df)):]\n",
    "\n",
    "y_test = list([gender_to_int[gender] for gender in clean_df['gender'][int(0.9*len(clean_df)):]]) \n",
    "\n",
    "texts_for_keras_tokenizer = list([' '.join(tokenizer.tokenize(text)) for text in x_test]) \n",
    "\n",
    "\n",
    "x_test = keras_tokenizer.texts_to_matrix(texts_for_keras_tokenizer, mode='binary')\n",
    "\n",
    "keras_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.68      0.69       619\n",
      "          1       0.57      0.52      0.54       425\n",
      "          2       0.67      0.84      0.74       273\n",
      "\n",
      "avg / total       0.66      0.66      0.66      1317\n",
      "\n",
      "Accuracy score: 0.659832953682612\n"
     ]
    }
   ],
   "source": [
    "int_to_gender = {0: 'female',1:'male',2:'brand'}\n",
    "\n",
    "actual_pred = list([np.argmax(values) for values in keras_pred])\n",
    "\n",
    "#todo write things\n",
    "print(classification_report(y_test, actual_pred))\n",
    "print('Accuracy score: {}'.format(accuracy_score(y_test, actual_pred)))"
   ]
  },
  {
   "attachments": {
    "Untitled.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Untitled.png](attachment:Untitled.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessing_combinations(df_training, df_test):\n",
    "    #this produces a list of tuples which are all the possible arrangements of True,False among the cleaning steps we will use\n",
    "    parameter_possibilities = list(itertools.product([0, 1], repeat=7))\n",
    "    \n",
    "    lower_possibility_index = 0\n",
    "    stem_possibility_index = 1\n",
    "    remove_stop_words_possibility_index = 2\n",
    "    remove_url_possibility_index = 3\n",
    "    remove_punctuation_possibility_index = 4\n",
    "    remove_hashtags_possibility_index = 5\n",
    "    remove_ats_possibility_index = 6\n",
    "\n",
    "    #this will be a list of tuples.\n",
    "    res = []\n",
    "    \n",
    "    for possibility in parameter_possibilities:\n",
    "        is_lower = bool(possibility[lower_possibility_index])\n",
    "        is_stemming = bool(possibility[stem_possibility_index])\n",
    "        is_remove_stop_words = bool(possibility[remove_stop_words_possibility_index])\n",
    "        is_remove_url = bool(possibility[remove_url_possibility_index])\n",
    "        is_remove_punctuation = bool(possibility[remove_punctuation_possibility_index])\n",
    "        is_remove_hashtags = bool(possibility[remove_hashtags_possibility_index])\n",
    "        is_remove_hashtags = 'only_symbol' if is_remove_hashtags else 'none'\n",
    "        is_remove_ats = bool(possibility[remove_ats_possibility_index])\n",
    "        is_remove_ats = 'entire_expression' if is_remove_ats else 'none'\n",
    "\n",
    "        \n",
    "        current_training  = preprocess(df_training, \n",
    "                                       should_lower=is_lower,\n",
    "                                       should_stem=is_stemming,\n",
    "                                       should_remove_stop_words=is_remove_stop_words,\n",
    "                                       should_remove_url=is_remove_url,\n",
    "                                       should_remove_punctuation=is_remove_punctuation,\n",
    "                                       should_remove_hashtags = is_remove_hashtags,\n",
    "                                       should_remove_ats = is_remove_ats)\n",
    "        current_test  = preprocess(df_test, \n",
    "                                       should_lower=is_lower,\n",
    "                                       should_stem=is_stemming,\n",
    "                                       should_remove_stop_words=is_remove_stop_words,\n",
    "                                       should_remove_url=is_remove_url,\n",
    "                                       should_remove_punctuation=is_remove_punctuation,\n",
    "                                       should_remove_hashtags = is_remove_hashtags,\n",
    "                                       should_remove_ats = is_remove_ats)\n",
    "\n",
    "        current_tag= '\\nlower : ' + str(is_lower)\n",
    "        current_tag+= '\\nstemming : ' + str(is_stemming)\n",
    "        current_tag+= '\\nremove stop words : '+str(is_remove_stop_words)\n",
    "        current_tag+= '\\nremove urls : '+str(is_remove_url)\n",
    "        current_tag+= '\\nremove punctuation : '+str(is_remove_punctuation)\n",
    "        current_tag+= '\\nremove hashtags : '+str(is_remove_hashtags)\n",
    "        current_tag+= '\\nremove ats : '+str(is_remove_ats)\n",
    "\n",
    "        tagged_clean_dataset = (current_training , current_test , current_tag)\n",
    "        \n",
    "        res.append(tagged_clean_dataset)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_df = clean_df[:int(0.9*len(clean_df))]#note that the df we use here was cleaned only from spam and irrelevant records. we will now clean it further\n",
    "test_df = clean_df[int(0.9*len(clean_df)):]\n",
    "\n",
    "combinations = preprocessing_combinations(training_df,test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with combination number 0/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.8130 - acc: 0.6079 - val_loss: 0.7096 - val_acc: 0.6675\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.5167 - acc: 0.7775 - val_loss: 0.7506 - val_acc: 0.6641\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 24s 2ms/step - loss: 0.2643 - acc: 0.9006 - val_loss: 0.9423 - val_acc: 0.6616\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 24s 2ms/step - loss: 0.1218 - acc: 0.9586 - val_loss: 1.2033 - val_acc: 0.6506\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 24s 2ms/step - loss: 0.0745 - acc: 0.9808 - val_loss: 1.2775 - val_acc: 0.6641\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0400 - acc: 0.9899 - val_loss: 1.5931 - val_acc: 0.6641\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0401 - acc: 0.9892 - val_loss: 1.5027 - val_acc: 0.6515\n",
      "Training with combination number 1/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.8204 - acc: 0.6116 - val_loss: 0.7177 - val_acc: 0.6506\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 24s 2ms/step - loss: 0.5177 - acc: 0.7829 - val_loss: 0.7377 - val_acc: 0.6743\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2733 - acc: 0.8966 - val_loss: 0.9328 - val_acc: 0.6565\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1267 - acc: 0.9592 - val_loss: 1.1377 - val_acc: 0.6675\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0682 - acc: 0.9807 - val_loss: 1.4633 - val_acc: 0.6414\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0506 - acc: 0.9864 - val_loss: 1.4557 - val_acc: 0.6557\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0371 - acc: 0.9913 - val_loss: 1.6966 - val_acc: 0.6380\n",
      "Training with combination number 2/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.8175 - acc: 0.6088 - val_loss: 0.7074 - val_acc: 0.6827\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.5047 - acc: 0.7882 - val_loss: 0.7425 - val_acc: 0.6709\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2706 - acc: 0.8989 - val_loss: 0.9453 - val_acc: 0.6641\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1226 - acc: 0.9599 - val_loss: 1.1798 - val_acc: 0.6616\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0735 - acc: 0.9793 - val_loss: 1.3810 - val_acc: 0.6658\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0427 - acc: 0.9882 - val_loss: 1.5646 - val_acc: 0.6582\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0465 - acc: 0.9889 - val_loss: 1.5748 - val_acc: 0.6464\n",
      "Training with combination number 3/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.8194 - acc: 0.6058 - val_loss: 0.7144 - val_acc: 0.6700\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.5063 - acc: 0.7885 - val_loss: 0.7674 - val_acc: 0.6582\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2789 - acc: 0.8937 - val_loss: 0.9529 - val_acc: 0.6641\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1282 - acc: 0.9583 - val_loss: 1.1495 - val_acc: 0.6456\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0607 - acc: 0.9827 - val_loss: 1.4299 - val_acc: 0.6549\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0493 - acc: 0.9867 - val_loss: 1.5403 - val_acc: 0.6582\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0417 - acc: 0.9891 - val_loss: 1.5176 - val_acc: 0.6591\n",
      "Training with combination number 4/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.8271 - acc: 0.5996 - val_loss: 0.7301 - val_acc: 0.6616\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.5139 - acc: 0.7860 - val_loss: 0.7751 - val_acc: 0.6540\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2630 - acc: 0.9006 - val_loss: 0.9525 - val_acc: 0.6675\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1152 - acc: 0.9644 - val_loss: 1.1875 - val_acc: 0.6473\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0660 - acc: 0.9807 - val_loss: 1.4667 - val_acc: 0.6506\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0427 - acc: 0.9890 - val_loss: 1.5720 - val_acc: 0.6709\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0402 - acc: 0.9896 - val_loss: 1.6380 - val_acc: 0.6380\n",
      "Training with combination number 5/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.8194 - acc: 0.5986 - val_loss: 0.7224 - val_acc: 0.6565\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.5147 - acc: 0.7837 - val_loss: 0.7695 - val_acc: 0.6667\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2635 - acc: 0.9017 - val_loss: 0.9641 - val_acc: 0.6549\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1190 - acc: 0.9616 - val_loss: 1.2336 - val_acc: 0.6582\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0592 - acc: 0.9837 - val_loss: 1.4354 - val_acc: 0.6608\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0505 - acc: 0.9865 - val_loss: 1.5357 - val_acc: 0.6447\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0426 - acc: 0.9887 - val_loss: 1.6220 - val_acc: 0.6540\n",
      "Training with combination number 6/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.8224 - acc: 0.6040 - val_loss: 0.7220 - val_acc: 0.6684\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.5083 - acc: 0.7898 - val_loss: 0.7696 - val_acc: 0.6751\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2640 - acc: 0.9009 - val_loss: 0.9162 - val_acc: 0.6700\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1121 - acc: 0.9626 - val_loss: 1.2408 - val_acc: 0.6464\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0648 - acc: 0.9820 - val_loss: 1.3934 - val_acc: 0.6464\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0477 - acc: 0.9877 - val_loss: 1.4627 - val_acc: 0.6633\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0336 - acc: 0.9903 - val_loss: 1.6682 - val_acc: 0.6481\n",
      "Training with combination number 7/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.8172 - acc: 0.6115 - val_loss: 0.7137 - val_acc: 0.6658\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.5108 - acc: 0.7843 - val_loss: 0.7455 - val_acc: 0.6734\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2604 - acc: 0.9017 - val_loss: 0.9449 - val_acc: 0.6700\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1202 - acc: 0.9595 - val_loss: 1.2228 - val_acc: 0.6684\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0624 - acc: 0.9819 - val_loss: 1.4652 - val_acc: 0.6608\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0476 - acc: 0.9883 - val_loss: 1.5807 - val_acc: 0.6582\n",
      "Epoch 7/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0335 - acc: 0.9908 - val_loss: 1.7124 - val_acc: 0.6574\n",
      "Training with combination number 8/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.8156 - acc: 0.6066 - val_loss: 0.7179 - val_acc: 0.6464\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.5243 - acc: 0.7858 - val_loss: 0.7339 - val_acc: 0.6658\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2791 - acc: 0.8959 - val_loss: 0.9138 - val_acc: 0.6726\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1292 - acc: 0.9570 - val_loss: 1.1469 - val_acc: 0.6675\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0745 - acc: 0.9781 - val_loss: 1.3788 - val_acc: 0.6641\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0433 - acc: 0.9870 - val_loss: 1.4954 - val_acc: 0.6532\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0380 - acc: 0.9882 - val_loss: 1.5654 - val_acc: 0.6397\n",
      "Training with combination number 9/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.8183 - acc: 0.6049 - val_loss: 0.7194 - val_acc: 0.6616\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.5151 - acc: 0.7851 - val_loss: 0.7599 - val_acc: 0.6523\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2703 - acc: 0.8993 - val_loss: 0.9339 - val_acc: 0.6608\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1201 - acc: 0.9594 - val_loss: 1.1714 - val_acc: 0.6532\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0694 - acc: 0.9809 - val_loss: 1.3466 - val_acc: 0.6591\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0544 - acc: 0.9835 - val_loss: 1.3995 - val_acc: 0.6473\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0367 - acc: 0.9910 - val_loss: 1.5238 - val_acc: 0.6624\n",
      "Training with combination number 10/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.8182 - acc: 0.6072 - val_loss: 0.7359 - val_acc: 0.6397\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.5163 - acc: 0.7840 - val_loss: 0.7535 - val_acc: 0.6700\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2777 - acc: 0.8944 - val_loss: 0.8743 - val_acc: 0.6692\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1201 - acc: 0.9593 - val_loss: 1.1273 - val_acc: 0.6759\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0683 - acc: 0.9781 - val_loss: 1.3816 - val_acc: 0.6549\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0492 - acc: 0.9853 - val_loss: 1.4831 - val_acc: 0.6650\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0355 - acc: 0.9900 - val_loss: 1.5175 - val_acc: 0.6802\n",
      "Training with combination number 11/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.8127 - acc: 0.6114 - val_loss: 0.7215 - val_acc: 0.6549\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.5161 - acc: 0.7843 - val_loss: 0.7671 - val_acc: 0.6658\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2706 - acc: 0.8960 - val_loss: 0.9479 - val_acc: 0.6726\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1239 - acc: 0.9571 - val_loss: 1.1833 - val_acc: 0.6523\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0754 - acc: 0.9778 - val_loss: 1.3825 - val_acc: 0.6700\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0473 - acc: 0.9878 - val_loss: 1.4857 - val_acc: 0.6599\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0392 - acc: 0.9911 - val_loss: 1.6024 - val_acc: 0.6532\n",
      "Training with combination number 12/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.8172 - acc: 0.6024 - val_loss: 0.7209 - val_acc: 0.6709\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.5110 - acc: 0.7867 - val_loss: 0.7614 - val_acc: 0.6776\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2634 - acc: 0.9011 - val_loss: 0.9865 - val_acc: 0.6414\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1226 - acc: 0.9620 - val_loss: 1.2284 - val_acc: 0.6523\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0605 - acc: 0.9811 - val_loss: 1.5262 - val_acc: 0.6532\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0420 - acc: 0.9881 - val_loss: 1.5623 - val_acc: 0.6624\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0381 - acc: 0.9900 - val_loss: 1.6521 - val_acc: 0.6338\n",
      "Training with combination number 13/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.8205 - acc: 0.6051 - val_loss: 0.7295 - val_acc: 0.6557\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.5125 - acc: 0.7812 - val_loss: 0.7667 - val_acc: 0.6692\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2640 - acc: 0.8999 - val_loss: 0.9125 - val_acc: 0.6624\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1238 - acc: 0.9604 - val_loss: 1.1947 - val_acc: 0.6557\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0638 - acc: 0.9831 - val_loss: 1.4811 - val_acc: 0.6599\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0512 - acc: 0.9851 - val_loss: 1.5235 - val_acc: 0.6515\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0414 - acc: 0.9901 - val_loss: 1.6111 - val_acc: 0.6650\n",
      "Training with combination number 14/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.8189 - acc: 0.5977 - val_loss: 0.7159 - val_acc: 0.6717\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.5151 - acc: 0.7854 - val_loss: 0.7550 - val_acc: 0.6684\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.2680 - acc: 0.9000 - val_loss: 0.9295 - val_acc: 0.6684\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 34090s 3s/step - loss: 0.1170 - acc: 0.9623 - val_loss: 1.2135 - val_acc: 0.6675\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0640 - acc: 0.9819 - val_loss: 1.4393 - val_acc: 0.6532\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0432 - acc: 0.9870 - val_loss: 1.5382 - val_acc: 0.6532\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0369 - acc: 0.9917 - val_loss: 1.5904 - val_acc: 0.6388\n",
      "Training with combination number 15/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.8166 - acc: 0.6152 - val_loss: 0.7260 - val_acc: 0.6624\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.5117 - acc: 0.7873 - val_loss: 0.7502 - val_acc: 0.6810\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2618 - acc: 0.9033 - val_loss: 0.9059 - val_acc: 0.6684\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.1219 - acc: 0.9606 - val_loss: 1.1740 - val_acc: 0.6667\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0616 - acc: 0.9825 - val_loss: 1.3674 - val_acc: 0.6599\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 27s 2ms/step - loss: 0.0464 - acc: 0.9891 - val_loss: 1.5063 - val_acc: 0.6759\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0335 - acc: 0.9920 - val_loss: 1.5875 - val_acc: 0.6624\n",
      "Training with combination number 16/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.8212 - acc: 0.6020 - val_loss: 0.7337 - val_acc: 0.6549\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.4913 - acc: 0.7964 - val_loss: 0.7723 - val_acc: 0.6624\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2429 - acc: 0.9088 - val_loss: 1.0309 - val_acc: 0.6616\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1049 - acc: 0.9672 - val_loss: 1.3320 - val_acc: 0.6591\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0551 - acc: 0.9833 - val_loss: 1.5098 - val_acc: 0.6675\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0418 - acc: 0.9903 - val_loss: 1.6835 - val_acc: 0.6489\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0329 - acc: 0.9927 - val_loss: 1.8010 - val_acc: 0.6515\n",
      "Training with combination number 17/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.8248 - acc: 0.6047 - val_loss: 0.7183 - val_acc: 0.6692\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 24s 2ms/step - loss: 0.5034 - acc: 0.7887 - val_loss: 0.7737 - val_acc: 0.6430\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 24s 2ms/step - loss: 0.2552 - acc: 0.9038 - val_loss: 1.0046 - val_acc: 0.6616\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1057 - acc: 0.9663 - val_loss: 1.3456 - val_acc: 0.6456\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0609 - acc: 0.9823 - val_loss: 1.5039 - val_acc: 0.6549\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0416 - acc: 0.9889 - val_loss: 1.7158 - val_acc: 0.6540\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0354 - acc: 0.9906 - val_loss: 1.7629 - val_acc: 0.6388\n",
      "Training with combination number 18/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.8224 - acc: 0.6050 - val_loss: 0.7220 - val_acc: 0.6633\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.4944 - acc: 0.7969 - val_loss: 0.7727 - val_acc: 0.6557\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2468 - acc: 0.9087 - val_loss: 0.9960 - val_acc: 0.6650\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 24s 2ms/step - loss: 0.1011 - acc: 0.9682 - val_loss: 1.3212 - val_acc: 0.6515\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 24s 2ms/step - loss: 0.0614 - acc: 0.9828 - val_loss: 1.4924 - val_acc: 0.6489\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 24s 2ms/step - loss: 0.0451 - acc: 0.9892 - val_loss: 1.6082 - val_acc: 0.6608\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 24s 2ms/step - loss: 0.0348 - acc: 0.9914 - val_loss: 1.7899 - val_acc: 0.6523\n",
      "Training with combination number 19/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.8222 - acc: 0.6014 - val_loss: 0.7254 - val_acc: 0.6641\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 24s 2ms/step - loss: 0.4950 - acc: 0.7978 - val_loss: 0.8031 - val_acc: 0.6776\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 24s 2ms/step - loss: 0.2473 - acc: 0.9079 - val_loss: 0.9974 - val_acc: 0.6726\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 24s 2ms/step - loss: 0.1034 - acc: 0.9679 - val_loss: 1.2374 - val_acc: 0.6532\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 24s 2ms/step - loss: 0.0555 - acc: 0.9845 - val_loss: 1.5047 - val_acc: 0.6616\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0420 - acc: 0.9886 - val_loss: 1.6068 - val_acc: 0.6473\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 24s 2ms/step - loss: 0.0357 - acc: 0.9911 - val_loss: 1.6798 - val_acc: 0.6371\n",
      "Training with combination number 20/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.8269 - acc: 0.5954 - val_loss: 0.7335 - val_acc: 0.6616\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 24s 2ms/step - loss: 0.4868 - acc: 0.8004 - val_loss: 0.7788 - val_acc: 0.6616\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2346 - acc: 0.9177 - val_loss: 1.0642 - val_acc: 0.6253\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1022 - acc: 0.9685 - val_loss: 1.3305 - val_acc: 0.6489\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0622 - acc: 0.9836 - val_loss: 1.5507 - val_acc: 0.6439\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 24s 2ms/step - loss: 0.0352 - acc: 0.9904 - val_loss: 1.7436 - val_acc: 0.6363\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 24s 2ms/step - loss: 0.0302 - acc: 0.9924 - val_loss: 1.9152 - val_acc: 0.6481\n",
      "Training with combination number 21/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.8322 - acc: 0.5928 - val_loss: 0.7378 - val_acc: 0.6658\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.4937 - acc: 0.7969 - val_loss: 0.8090 - val_acc: 0.6624\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2368 - acc: 0.9142 - val_loss: 1.0485 - val_acc: 0.6464\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1058 - acc: 0.9666 - val_loss: 1.3339 - val_acc: 0.6422\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0600 - acc: 0.9839 - val_loss: 1.5508 - val_acc: 0.6414\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0393 - acc: 0.9902 - val_loss: 1.6938 - val_acc: 0.6489\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0352 - acc: 0.9917 - val_loss: 1.8185 - val_acc: 0.6447\n",
      "Training with combination number 22/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.8217 - acc: 0.5996 - val_loss: 0.7471 - val_acc: 0.6481\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.4842 - acc: 0.8000 - val_loss: 0.7893 - val_acc: 0.6430\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2340 - acc: 0.9143 - val_loss: 1.0354 - val_acc: 0.6397\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0980 - acc: 0.9683 - val_loss: 1.3091 - val_acc: 0.6473\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0567 - acc: 0.9844 - val_loss: 1.5202 - val_acc: 0.6464\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 24s 2ms/step - loss: 0.0409 - acc: 0.9882 - val_loss: 1.7057 - val_acc: 0.6473\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 24s 2ms/step - loss: 0.0345 - acc: 0.9907 - val_loss: 1.7304 - val_acc: 0.6557\n",
      "Training with combination number 23/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.8185 - acc: 0.6039 - val_loss: 0.7345 - val_acc: 0.6650\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.4868 - acc: 0.7976 - val_loss: 0.7939 - val_acc: 0.6599\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2423 - acc: 0.9116 - val_loss: 1.0074 - val_acc: 0.6591\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 24s 2ms/step - loss: 0.0969 - acc: 0.9683 - val_loss: 1.3623 - val_acc: 0.6430\n",
      "Epoch 5/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 24s 2ms/step - loss: 0.0570 - acc: 0.9845 - val_loss: 1.5199 - val_acc: 0.6498\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0409 - acc: 0.9888 - val_loss: 1.6663 - val_acc: 0.6439\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 24s 2ms/step - loss: 0.0391 - acc: 0.9892 - val_loss: 1.7253 - val_acc: 0.6388\n",
      "Training with combination number 24/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.8237 - acc: 0.6032 - val_loss: 0.7286 - val_acc: 0.6658\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.5065 - acc: 0.7932 - val_loss: 0.7606 - val_acc: 0.6785\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2450 - acc: 0.9110 - val_loss: 1.0025 - val_acc: 0.6540\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1100 - acc: 0.9659 - val_loss: 1.2753 - val_acc: 0.6675\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0598 - acc: 0.9832 - val_loss: 1.4846 - val_acc: 0.6608\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0398 - acc: 0.9902 - val_loss: 1.6475 - val_acc: 0.6481\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 24s 2ms/step - loss: 0.0352 - acc: 0.9917 - val_loss: 1.6469 - val_acc: 0.6591\n",
      "Training with combination number 25/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.8277 - acc: 0.6015 - val_loss: 0.7309 - val_acc: 0.6608\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.5034 - acc: 0.7889 - val_loss: 0.7738 - val_acc: 0.6422\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2557 - acc: 0.9066 - val_loss: 1.0261 - val_acc: 0.6557\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1133 - acc: 0.9633 - val_loss: 1.2733 - val_acc: 0.6574\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0589 - acc: 0.9833 - val_loss: 1.4553 - val_acc: 0.6422\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0423 - acc: 0.9891 - val_loss: 1.6248 - val_acc: 0.6464\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0360 - acc: 0.9904 - val_loss: 1.6487 - val_acc: 0.6422\n",
      "Training with combination number 26/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.8276 - acc: 0.6029 - val_loss: 0.7262 - val_acc: 0.6549\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.4975 - acc: 0.7937 - val_loss: 0.7850 - val_acc: 0.6582\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2410 - acc: 0.9098 - val_loss: 0.9742 - val_acc: 0.6658\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0975 - acc: 0.9675 - val_loss: 1.2704 - val_acc: 0.6388\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0598 - acc: 0.9848 - val_loss: 1.5186 - val_acc: 0.6574\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0404 - acc: 0.9900 - val_loss: 1.6193 - val_acc: 0.6616\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0348 - acc: 0.9900 - val_loss: 1.6939 - val_acc: 0.6532\n",
      "Training with combination number 27/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.8240 - acc: 0.6027 - val_loss: 0.7337 - val_acc: 0.6574\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.4925 - acc: 0.8012 - val_loss: 0.7562 - val_acc: 0.6734\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2420 - acc: 0.9114 - val_loss: 0.9797 - val_acc: 0.6658\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1036 - acc: 0.9669 - val_loss: 1.2902 - val_acc: 0.6582\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0516 - acc: 0.9856 - val_loss: 1.5028 - val_acc: 0.6582\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0423 - acc: 0.9887 - val_loss: 1.6729 - val_acc: 0.6473\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0319 - acc: 0.9918 - val_loss: 1.7750 - val_acc: 0.6430\n",
      "Training with combination number 28/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 27s 3ms/step - loss: 0.8249 - acc: 0.6041 - val_loss: 0.7459 - val_acc: 0.6489\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.4933 - acc: 0.7961 - val_loss: 0.7979 - val_acc: 0.6633\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2392 - acc: 0.9133 - val_loss: 1.0209 - val_acc: 0.6447\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1029 - acc: 0.9685 - val_loss: 1.3203 - val_acc: 0.6506\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0592 - acc: 0.9836 - val_loss: 1.5326 - val_acc: 0.6439\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0423 - acc: 0.9895 - val_loss: 1.7462 - val_acc: 0.6338\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0350 - acc: 0.9919 - val_loss: 1.8514 - val_acc: 0.6203\n",
      "Training with combination number 29/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 27s 3ms/step - loss: 0.8348 - acc: 0.5987 - val_loss: 0.7369 - val_acc: 0.6565\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.4923 - acc: 0.7975 - val_loss: 0.8034 - val_acc: 0.6574\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2362 - acc: 0.9152 - val_loss: 1.0149 - val_acc: 0.6591\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1109 - acc: 0.9650 - val_loss: 1.2807 - val_acc: 0.6439\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0586 - acc: 0.9837 - val_loss: 1.5654 - val_acc: 0.6363\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0394 - acc: 0.9892 - val_loss: 1.7903 - val_acc: 0.6354\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0404 - acc: 0.9906 - val_loss: 1.7595 - val_acc: 0.6388\n",
      "Training with combination number 30/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.8276 - acc: 0.6015 - val_loss: 0.7362 - val_acc: 0.6540\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.4918 - acc: 0.8016 - val_loss: 0.8294 - val_acc: 0.6405\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2465 - acc: 0.9093 - val_loss: 1.0268 - val_acc: 0.6405\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1044 - acc: 0.9653 - val_loss: 1.3433 - val_acc: 0.6430\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0544 - acc: 0.9848 - val_loss: 1.5535 - val_acc: 0.6506\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0466 - acc: 0.9887 - val_loss: 1.6637 - val_acc: 0.6489\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0333 - acc: 0.9924 - val_loss: 1.7584 - val_acc: 0.6481\n",
      "Training with combination number 31/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.8274 - acc: 0.5973 - val_loss: 0.7282 - val_acc: 0.6650\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.4914 - acc: 0.8012 - val_loss: 0.7978 - val_acc: 0.6633\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2333 - acc: 0.9137 - val_loss: 1.0726 - val_acc: 0.6464\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1048 - acc: 0.9664 - val_loss: 1.3223 - val_acc: 0.6557\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0567 - acc: 0.9845 - val_loss: 1.4744 - val_acc: 0.6624\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0386 - acc: 0.9905 - val_loss: 1.6925 - val_acc: 0.6565\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0301 - acc: 0.9928 - val_loss: 1.8043 - val_acc: 0.6430\n",
      "Training with combination number 32/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.8301 - acc: 0.5969 - val_loss: 0.7336 - val_acc: 0.6540\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.5408 - acc: 0.7747 - val_loss: 0.7699 - val_acc: 0.6481\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.2961 - acc: 0.8882 - val_loss: 0.9677 - val_acc: 0.6473\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.1390 - acc: 0.9545 - val_loss: 1.1303 - val_acc: 0.6422\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0710 - acc: 0.9776 - val_loss: 1.3055 - val_acc: 0.6515\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0492 - acc: 0.9874 - val_loss: 1.5098 - val_acc: 0.6523\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0460 - acc: 0.9870 - val_loss: 1.5828 - val_acc: 0.6295\n",
      "Training with combination number 33/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 27s 3ms/step - loss: 0.8206 - acc: 0.6033 - val_loss: 0.7353 - val_acc: 0.6658\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.5424 - acc: 0.7746 - val_loss: 0.7981 - val_acc: 0.6405\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.3066 - acc: 0.8831 - val_loss: 0.8734 - val_acc: 0.6473\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1417 - acc: 0.9506 - val_loss: 1.1399 - val_acc: 0.6549\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0765 - acc: 0.9792 - val_loss: 1.4861 - val_acc: 0.6397\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0605 - acc: 0.9826 - val_loss: 1.5100 - val_acc: 0.6464\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0424 - acc: 0.9887 - val_loss: 1.5866 - val_acc: 0.6557\n",
      "Training with combination number 34/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 28s 3ms/step - loss: 0.8227 - acc: 0.6069 - val_loss: 0.7329 - val_acc: 0.6599\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 27s 2ms/step - loss: 0.5374 - acc: 0.7742 - val_loss: 0.7783 - val_acc: 0.6414\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.3058 - acc: 0.8835 - val_loss: 0.9181 - val_acc: 0.6456\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.1457 - acc: 0.9493 - val_loss: 1.1142 - val_acc: 0.6439\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0719 - acc: 0.9788 - val_loss: 1.4210 - val_acc: 0.6473\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0479 - acc: 0.9862 - val_loss: 1.5018 - val_acc: 0.6346\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0403 - acc: 0.9901 - val_loss: 1.5979 - val_acc: 0.6422\n",
      "Training with combination number 35/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 27s 3ms/step - loss: 0.8270 - acc: 0.6011 - val_loss: 0.7294 - val_acc: 0.6481\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.5446 - acc: 0.7662 - val_loss: 0.7587 - val_acc: 0.6549\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.3001 - acc: 0.8831 - val_loss: 0.9515 - val_acc: 0.6380\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.1325 - acc: 0.9527 - val_loss: 1.2161 - val_acc: 0.6414\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0827 - acc: 0.9760 - val_loss: 1.4345 - val_acc: 0.6498\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0522 - acc: 0.9859 - val_loss: 1.5320 - val_acc: 0.6422\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0399 - acc: 0.9886 - val_loss: 1.6780 - val_acc: 0.6414\n",
      "Training with combination number 36/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.8254 - acc: 0.6030 - val_loss: 0.7464 - val_acc: 0.6574\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.5408 - acc: 0.7723 - val_loss: 0.7616 - val_acc: 0.6658\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2976 - acc: 0.8894 - val_loss: 0.9204 - val_acc: 0.6422\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1421 - acc: 0.9520 - val_loss: 1.2283 - val_acc: 0.6447\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0682 - acc: 0.9796 - val_loss: 1.4667 - val_acc: 0.6447\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0532 - acc: 0.9850 - val_loss: 1.5365 - val_acc: 0.6354\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0446 - acc: 0.9890 - val_loss: 1.6702 - val_acc: 0.6380\n",
      "Training with combination number 37/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 27s 3ms/step - loss: 0.8305 - acc: 0.5980 - val_loss: 0.7499 - val_acc: 0.6557\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.5350 - acc: 0.7772 - val_loss: 0.7745 - val_acc: 0.6591\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.2925 - acc: 0.8898 - val_loss: 0.9993 - val_acc: 0.6346\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1403 - acc: 0.9532 - val_loss: 1.1934 - val_acc: 0.6346\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0736 - acc: 0.9782 - val_loss: 1.3320 - val_acc: 0.6422\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0583 - acc: 0.9857 - val_loss: 1.4931 - val_acc: 0.6388\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0387 - acc: 0.9902 - val_loss: 1.7495 - val_acc: 0.6321\n",
      "Training with combination number 38/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.8279 - acc: 0.6007 - val_loss: 0.7310 - val_acc: 0.6574\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.5391 - acc: 0.7738 - val_loss: 0.7634 - val_acc: 0.6692\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2906 - acc: 0.8894 - val_loss: 0.9278 - val_acc: 0.6532\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1313 - acc: 0.9561 - val_loss: 1.2683 - val_acc: 0.6312\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0690 - acc: 0.9782 - val_loss: 1.4311 - val_acc: 0.6498\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0469 - acc: 0.9877 - val_loss: 1.5503 - val_acc: 0.6540\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0368 - acc: 0.9885 - val_loss: 1.6850 - val_acc: 0.6515\n",
      "Training with combination number 39/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 28s 3ms/step - loss: 0.8313 - acc: 0.5990 - val_loss: 0.7598 - val_acc: 0.6439\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.5386 - acc: 0.7708 - val_loss: 0.7670 - val_acc: 0.6430\n",
      "Epoch 3/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2940 - acc: 0.8874 - val_loss: 0.9469 - val_acc: 0.6481\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1306 - acc: 0.9558 - val_loss: 1.2395 - val_acc: 0.6481\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0716 - acc: 0.9781 - val_loss: 1.5237 - val_acc: 0.6245\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0486 - acc: 0.9877 - val_loss: 1.7100 - val_acc: 0.6219\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0349 - acc: 0.9899 - val_loss: 1.6884 - val_acc: 0.6346\n",
      "Training with combination number 40/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 29s 3ms/step - loss: 0.8243 - acc: 0.6040 - val_loss: 0.7255 - val_acc: 0.6658\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.5402 - acc: 0.7719 - val_loss: 0.7772 - val_acc: 0.6549\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 27s 2ms/step - loss: 0.3023 - acc: 0.8840 - val_loss: 0.9158 - val_acc: 0.6464\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.1406 - acc: 0.9550 - val_loss: 1.1315 - val_acc: 0.6498\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0801 - acc: 0.9760 - val_loss: 1.2761 - val_acc: 0.6464\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 27s 3ms/step - loss: 0.0504 - acc: 0.9852 - val_loss: 1.5060 - val_acc: 0.6338\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0385 - acc: 0.9902 - val_loss: 1.6424 - val_acc: 0.6354\n",
      "Training with combination number 41/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 27s 3ms/step - loss: 0.8218 - acc: 0.6101 - val_loss: 0.7412 - val_acc: 0.6557\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.5392 - acc: 0.7681 - val_loss: 0.7601 - val_acc: 0.6599\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2969 - acc: 0.8895 - val_loss: 0.8946 - val_acc: 0.6523\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1392 - acc: 0.9534 - val_loss: 1.1544 - val_acc: 0.6549\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0700 - acc: 0.9796 - val_loss: 1.3621 - val_acc: 0.6506\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0540 - acc: 0.9867 - val_loss: 1.4918 - val_acc: 0.6506\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0417 - acc: 0.9888 - val_loss: 1.5808 - val_acc: 0.6481\n",
      "Training with combination number 42/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 27s 3ms/step - loss: 0.8237 - acc: 0.6031 - val_loss: 0.7298 - val_acc: 0.6489\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.5351 - acc: 0.7767 - val_loss: 0.7404 - val_acc: 0.6574\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.2958 - acc: 0.8919 - val_loss: 0.9478 - val_acc: 0.6397\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.1313 - acc: 0.9574 - val_loss: 1.1986 - val_acc: 0.6532\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0725 - acc: 0.9793 - val_loss: 1.4478 - val_acc: 0.6371\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0522 - acc: 0.9857 - val_loss: 1.5522 - val_acc: 0.6456\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0424 - acc: 0.9890 - val_loss: 1.6531 - val_acc: 0.6262\n",
      "Training with combination number 43/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 27s 3ms/step - loss: 0.8249 - acc: 0.6077 - val_loss: 0.7347 - val_acc: 0.6532\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.5408 - acc: 0.7711 - val_loss: 0.7558 - val_acc: 0.6532\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2959 - acc: 0.8891 - val_loss: 0.9264 - val_acc: 0.6439\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1371 - acc: 0.9543 - val_loss: 1.1565 - val_acc: 0.6540\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0805 - acc: 0.9741 - val_loss: 1.4190 - val_acc: 0.6414\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0485 - acc: 0.9861 - val_loss: 1.4744 - val_acc: 0.6624\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0406 - acc: 0.9898 - val_loss: 1.6087 - val_acc: 0.6439\n",
      "Training with combination number 44/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 28s 3ms/step - loss: 0.8319 - acc: 0.5985 - val_loss: 0.7418 - val_acc: 0.6447\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.5426 - acc: 0.7749 - val_loss: 0.7682 - val_acc: 0.6489\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.3005 - acc: 0.8861 - val_loss: 0.9671 - val_acc: 0.6321\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.1312 - acc: 0.9571 - val_loss: 1.2292 - val_acc: 0.6346\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0732 - acc: 0.9789 - val_loss: 1.4286 - val_acc: 0.6430\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0492 - acc: 0.9864 - val_loss: 1.5985 - val_acc: 0.6430\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0447 - acc: 0.9894 - val_loss: 1.6430 - val_acc: 0.6456\n",
      "Training with combination number 45/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 28s 3ms/step - loss: 0.8293 - acc: 0.5993 - val_loss: 0.7455 - val_acc: 0.6422\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.5392 - acc: 0.7754 - val_loss: 0.7613 - val_acc: 0.6506\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.2960 - acc: 0.8885 - val_loss: 0.9372 - val_acc: 0.6473\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1400 - acc: 0.9542 - val_loss: 1.1691 - val_acc: 0.6447\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0744 - acc: 0.9782 - val_loss: 1.3545 - val_acc: 0.6414\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0532 - acc: 0.9842 - val_loss: 1.5307 - val_acc: 0.6430\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0451 - acc: 0.9888 - val_loss: 1.5773 - val_acc: 0.6388\n",
      "Training with combination number 46/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 28s 3ms/step - loss: 0.8255 - acc: 0.6056 - val_loss: 0.7555 - val_acc: 0.6481\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 27s 2ms/step - loss: 0.5379 - acc: 0.7776 - val_loss: 0.7908 - val_acc: 0.6489\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 27s 2ms/step - loss: 0.2869 - acc: 0.8935 - val_loss: 0.9565 - val_acc: 0.6414\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.1297 - acc: 0.9569 - val_loss: 1.1811 - val_acc: 0.6312\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0702 - acc: 0.9813 - val_loss: 1.4195 - val_acc: 0.6312\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0459 - acc: 0.9866 - val_loss: 1.6362 - val_acc: 0.6481\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0404 - acc: 0.9898 - val_loss: 1.6733 - val_acc: 0.6338\n",
      "Training with combination number 47/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 28s 3ms/step - loss: 0.8309 - acc: 0.5976 - val_loss: 0.7396 - val_acc: 0.6380\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.5389 - acc: 0.7745 - val_loss: 0.7663 - val_acc: 0.6532\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2893 - acc: 0.8901 - val_loss: 1.0140 - val_acc: 0.6557\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.1361 - acc: 0.9555 - val_loss: 1.2091 - val_acc: 0.6354\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0745 - acc: 0.9778 - val_loss: 1.3853 - val_acc: 0.6354\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0536 - acc: 0.9857 - val_loss: 1.5150 - val_acc: 0.6430\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0387 - acc: 0.9884 - val_loss: 1.7105 - val_acc: 0.6532\n",
      "Training with combination number 48/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 28s 3ms/step - loss: 0.8262 - acc: 0.6067 - val_loss: 0.7507 - val_acc: 0.6523\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.5223 - acc: 0.7846 - val_loss: 0.8092 - val_acc: 0.6481\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.2790 - acc: 0.8943 - val_loss: 0.9940 - val_acc: 0.6430\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1255 - acc: 0.9594 - val_loss: 1.2736 - val_acc: 0.6405\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0603 - acc: 0.9818 - val_loss: 1.5755 - val_acc: 0.6354\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0467 - acc: 0.9875 - val_loss: 1.7393 - val_acc: 0.6405\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0398 - acc: 0.9897 - val_loss: 1.7925 - val_acc: 0.6397\n",
      "Training with combination number 49/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 28s 3ms/step - loss: 0.8336 - acc: 0.5988 - val_loss: 0.7548 - val_acc: 0.6439\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.5296 - acc: 0.7766 - val_loss: 0.7996 - val_acc: 0.6321\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2816 - acc: 0.8957 - val_loss: 0.9495 - val_acc: 0.6439\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.1219 - acc: 0.9601 - val_loss: 1.2399 - val_acc: 0.6346\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0675 - acc: 0.9813 - val_loss: 1.4684 - val_acc: 0.6338\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0476 - acc: 0.9871 - val_loss: 1.6544 - val_acc: 0.6278\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0325 - acc: 0.9917 - val_loss: 1.7352 - val_acc: 0.6329\n",
      "Training with combination number 50/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 27s 3ms/step - loss: 0.8329 - acc: 0.6003 - val_loss: 0.7531 - val_acc: 0.6422\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.5217 - acc: 0.7835 - val_loss: 0.7859 - val_acc: 0.6599\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2671 - acc: 0.8990 - val_loss: 1.0530 - val_acc: 0.6354\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1241 - acc: 0.9615 - val_loss: 1.2142 - val_acc: 0.6405\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0590 - acc: 0.9819 - val_loss: 1.5025 - val_acc: 0.6354\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0446 - acc: 0.9888 - val_loss: 1.5990 - val_acc: 0.6287\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0392 - acc: 0.9913 - val_loss: 1.7435 - val_acc: 0.6287\n",
      "Training with combination number 51/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 27s 3ms/step - loss: 0.8344 - acc: 0.5960 - val_loss: 0.7453 - val_acc: 0.6549\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.5188 - acc: 0.7898 - val_loss: 0.7927 - val_acc: 0.6591\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2721 - acc: 0.8993 - val_loss: 0.9764 - val_acc: 0.6456\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.1205 - acc: 0.9617 - val_loss: 1.3032 - val_acc: 0.6321\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0669 - acc: 0.9801 - val_loss: 1.5224 - val_acc: 0.6371\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0473 - acc: 0.9884 - val_loss: 1.6456 - val_acc: 0.6304\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 27s 2ms/step - loss: 0.0365 - acc: 0.9890 - val_loss: 1.7503 - val_acc: 0.6287\n",
      "Training with combination number 52/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 29s 3ms/step - loss: 0.8373 - acc: 0.5949 - val_loss: 0.7639 - val_acc: 0.6371\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 27s 2ms/step - loss: 0.5271 - acc: 0.7837 - val_loss: 0.7994 - val_acc: 0.6523\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.2709 - acc: 0.8990 - val_loss: 1.0009 - val_acc: 0.6371\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 27s 2ms/step - loss: 0.1205 - acc: 0.9620 - val_loss: 1.2892 - val_acc: 0.6363\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0660 - acc: 0.9810 - val_loss: 1.4588 - val_acc: 0.6380\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0456 - acc: 0.9878 - val_loss: 1.7264 - val_acc: 0.6422\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0394 - acc: 0.9907 - val_loss: 1.7022 - val_acc: 0.6380\n",
      "Training with combination number 53/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 28s 3ms/step - loss: 0.8363 - acc: 0.5931 - val_loss: 0.7676 - val_acc: 0.6464\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.5249 - acc: 0.7843 - val_loss: 0.8123 - val_acc: 0.6473\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.2623 - acc: 0.9037 - val_loss: 1.0821 - val_acc: 0.6447\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.1186 - acc: 0.9592 - val_loss: 1.3982 - val_acc: 0.6312\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0645 - acc: 0.9805 - val_loss: 1.5678 - val_acc: 0.6422\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0436 - acc: 0.9881 - val_loss: 1.7315 - val_acc: 0.6430\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0319 - acc: 0.9925 - val_loss: 1.8961 - val_acc: 0.6363\n",
      "Training with combination number 54/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 27s 3ms/step - loss: 0.8391 - acc: 0.6034 - val_loss: 0.7570 - val_acc: 0.6489\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.5185 - acc: 0.7873 - val_loss: 0.8135 - val_acc: 0.6397\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2659 - acc: 0.8990 - val_loss: 1.0648 - val_acc: 0.6346\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1147 - acc: 0.9626 - val_loss: 1.4363 - val_acc: 0.6245\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0602 - acc: 0.9825 - val_loss: 1.6219 - val_acc: 0.6329\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0387 - acc: 0.9883 - val_loss: 1.8377 - val_acc: 0.6354\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0314 - acc: 0.9912 - val_loss: 1.8925 - val_acc: 0.6219\n",
      "Training with combination number 55/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 28s 3ms/step - loss: 0.8391 - acc: 0.5989 - val_loss: 0.7544 - val_acc: 0.6489\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.5248 - acc: 0.7862 - val_loss: 0.8277 - val_acc: 0.6287\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2728 - acc: 0.8936 - val_loss: 0.9962 - val_acc: 0.6363\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1193 - acc: 0.9628 - val_loss: 1.2958 - val_acc: 0.6354\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0616 - acc: 0.9826 - val_loss: 1.5327 - val_acc: 0.6143\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0435 - acc: 0.9892 - val_loss: 1.6976 - val_acc: 0.6219\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0380 - acc: 0.9905 - val_loss: 1.7571 - val_acc: 0.6278\n",
      "Training with combination number 56/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 29s 3ms/step - loss: 0.8345 - acc: 0.6057 - val_loss: 0.7533 - val_acc: 0.6371\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.5275 - acc: 0.7827 - val_loss: 0.7961 - val_acc: 0.6380\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2767 - acc: 0.8974 - val_loss: 0.9960 - val_acc: 0.6414\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1268 - acc: 0.9598 - val_loss: 1.3118 - val_acc: 0.6270\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0644 - acc: 0.9820 - val_loss: 1.4960 - val_acc: 0.6430\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0439 - acc: 0.9886 - val_loss: 1.6328 - val_acc: 0.6464\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0362 - acc: 0.9916 - val_loss: 1.6541 - val_acc: 0.6371\n",
      "Training with combination number 57/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 27s 3ms/step - loss: 0.8355 - acc: 0.5994 - val_loss: 0.7547 - val_acc: 0.6464\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.5192 - acc: 0.7835 - val_loss: 0.7912 - val_acc: 0.6481\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2785 - acc: 0.8971 - val_loss: 0.9387 - val_acc: 0.6422\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1198 - acc: 0.9619 - val_loss: 1.3173 - val_acc: 0.6414\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0687 - acc: 0.9796 - val_loss: 1.4723 - val_acc: 0.6312\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0469 - acc: 0.9878 - val_loss: 1.6483 - val_acc: 0.6422\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0384 - acc: 0.9901 - val_loss: 1.7876 - val_acc: 0.6295\n",
      "Training with combination number 58/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 29s 3ms/step - loss: 0.8319 - acc: 0.6040 - val_loss: 0.7580 - val_acc: 0.6405\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.5249 - acc: 0.7798 - val_loss: 0.7914 - val_acc: 0.6565\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2727 - acc: 0.8973 - val_loss: 1.0165 - val_acc: 0.6388\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1245 - acc: 0.9575 - val_loss: 1.2713 - val_acc: 0.6211\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0646 - acc: 0.9806 - val_loss: 1.5317 - val_acc: 0.6363\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0457 - acc: 0.9872 - val_loss: 1.6425 - val_acc: 0.6371\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0376 - acc: 0.9909 - val_loss: 1.7257 - val_acc: 0.6321\n",
      "Training with combination number 59/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 27s 3ms/step - loss: 0.8298 - acc: 0.6047 - val_loss: 0.7516 - val_acc: 0.6430\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.5230 - acc: 0.7830 - val_loss: 0.7965 - val_acc: 0.6515\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2728 - acc: 0.8991 - val_loss: 0.9905 - val_acc: 0.6430\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1216 - acc: 0.9605 - val_loss: 1.2802 - val_acc: 0.6380\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0656 - acc: 0.9798 - val_loss: 1.5577 - val_acc: 0.6245\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0479 - acc: 0.9866 - val_loss: 1.6392 - val_acc: 0.6312\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0368 - acc: 0.9896 - val_loss: 1.7041 - val_acc: 0.6371\n",
      "Training with combination number 60/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 27s 3ms/step - loss: 0.8315 - acc: 0.5970 - val_loss: 0.7577 - val_acc: 0.6439\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.5250 - acc: 0.7819 - val_loss: 0.8229 - val_acc: 0.6489\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2668 - acc: 0.8997 - val_loss: 1.0917 - val_acc: 0.6388\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1221 - acc: 0.9587 - val_loss: 1.3678 - val_acc: 0.6236\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0605 - acc: 0.9827 - val_loss: 1.6427 - val_acc: 0.6219\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0503 - acc: 0.9866 - val_loss: 1.7488 - val_acc: 0.6245\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0379 - acc: 0.9897 - val_loss: 1.8588 - val_acc: 0.6253\n",
      "Training with combination number 61/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 27s 3ms/step - loss: 0.8362 - acc: 0.5971 - val_loss: 0.7836 - val_acc: 0.6287\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.5265 - acc: 0.7796 - val_loss: 0.8301 - val_acc: 0.6304\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2707 - acc: 0.9006 - val_loss: 1.0085 - val_acc: 0.6422\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1217 - acc: 0.9621 - val_loss: 1.3418 - val_acc: 0.6354\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0668 - acc: 0.9803 - val_loss: 1.5677 - val_acc: 0.6329\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0431 - acc: 0.9872 - val_loss: 1.7248 - val_acc: 0.6295\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0361 - acc: 0.9913 - val_loss: 1.8450 - val_acc: 0.6397\n",
      "Training with combination number 62/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 28s 3ms/step - loss: 0.8306 - acc: 0.5983 - val_loss: 0.7567 - val_acc: 0.6549\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.5247 - acc: 0.7840 - val_loss: 0.8340 - val_acc: 0.6397\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.2639 - acc: 0.9009 - val_loss: 1.0551 - val_acc: 0.6439\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1157 - acc: 0.9625 - val_loss: 1.3848 - val_acc: 0.6262\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0660 - acc: 0.9800 - val_loss: 1.5937 - val_acc: 0.6371\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0463 - acc: 0.9880 - val_loss: 1.7841 - val_acc: 0.6245\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0358 - acc: 0.9919 - val_loss: 1.8437 - val_acc: 0.6430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with combination number 63/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 28s 3ms/step - loss: 0.8346 - acc: 0.6010 - val_loss: 0.7541 - val_acc: 0.6422\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.5179 - acc: 0.7786 - val_loss: 0.8113 - val_acc: 0.6380\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.2690 - acc: 0.8988 - val_loss: 1.0058 - val_acc: 0.6371\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.1207 - acc: 0.9600 - val_loss: 1.3509 - val_acc: 0.6338\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0661 - acc: 0.9809 - val_loss: 1.5490 - val_acc: 0.6321\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0431 - acc: 0.9876 - val_loss: 1.7015 - val_acc: 0.6439\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0440 - acc: 0.9893 - val_loss: 1.8235 - val_acc: 0.6338\n",
      "Training with combination number 64/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 27s 3ms/step - loss: 0.8175 - acc: 0.6111 - val_loss: 0.7360 - val_acc: 0.6523\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.5177 - acc: 0.7812 - val_loss: 0.7525 - val_acc: 0.6734\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2808 - acc: 0.8946 - val_loss: 0.8987 - val_acc: 0.6624\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1221 - acc: 0.9600 - val_loss: 1.1438 - val_acc: 0.6658\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0683 - acc: 0.9810 - val_loss: 1.3722 - val_acc: 0.6565\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0426 - acc: 0.9883 - val_loss: 1.5789 - val_acc: 0.6574\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0407 - acc: 0.9906 - val_loss: 1.5349 - val_acc: 0.6405\n",
      "Training with combination number 65/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 30s 3ms/step - loss: 0.8161 - acc: 0.6132 - val_loss: 0.7206 - val_acc: 0.6616\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.5122 - acc: 0.7893 - val_loss: 0.7645 - val_acc: 0.6591\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2717 - acc: 0.8991 - val_loss: 0.9249 - val_acc: 0.6582\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1264 - acc: 0.9568 - val_loss: 1.1528 - val_acc: 0.6684\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0651 - acc: 0.9801 - val_loss: 1.3215 - val_acc: 0.6633\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0498 - acc: 0.9864 - val_loss: 1.5332 - val_acc: 0.6616\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0347 - acc: 0.9909 - val_loss: 1.6255 - val_acc: 0.6473\n",
      "Training with combination number 66/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 27s 3ms/step - loss: 0.8111 - acc: 0.6120 - val_loss: 0.7099 - val_acc: 0.6624\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.5103 - acc: 0.7903 - val_loss: 0.7366 - val_acc: 0.6658\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2627 - acc: 0.9012 - val_loss: 0.9244 - val_acc: 0.6641\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1147 - acc: 0.9605 - val_loss: 1.1637 - val_acc: 0.6650\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0677 - acc: 0.9795 - val_loss: 1.3166 - val_acc: 0.6768\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0425 - acc: 0.9873 - val_loss: 1.5484 - val_acc: 0.6582\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0448 - acc: 0.9885 - val_loss: 1.5061 - val_acc: 0.6540\n",
      "Training with combination number 67/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 28s 3ms/step - loss: 0.8141 - acc: 0.6145 - val_loss: 0.7188 - val_acc: 0.6641\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.5108 - acc: 0.7863 - val_loss: 0.7474 - val_acc: 0.6844\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2680 - acc: 0.9002 - val_loss: 0.9047 - val_acc: 0.6709\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.1236 - acc: 0.9603 - val_loss: 1.1834 - val_acc: 0.6692\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0619 - acc: 0.9823 - val_loss: 1.4222 - val_acc: 0.6667\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0476 - acc: 0.9863 - val_loss: 1.5498 - val_acc: 0.6523\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0415 - acc: 0.9893 - val_loss: 1.5891 - val_acc: 0.6616\n",
      "Training with combination number 68/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 29s 3ms/step - loss: 0.8256 - acc: 0.6004 - val_loss: 0.7256 - val_acc: 0.6582\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.5157 - acc: 0.7847 - val_loss: 0.7616 - val_acc: 0.6675\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2704 - acc: 0.8978 - val_loss: 0.9374 - val_acc: 0.6810\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1169 - acc: 0.9616 - val_loss: 1.1883 - val_acc: 0.6616\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0672 - acc: 0.9812 - val_loss: 1.4085 - val_acc: 0.6422\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0501 - acc: 0.9870 - val_loss: 1.5121 - val_acc: 0.6574\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0373 - acc: 0.9922 - val_loss: 1.6011 - val_acc: 0.6616\n",
      "Training with combination number 69/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 27s 3ms/step - loss: 0.8232 - acc: 0.6088 - val_loss: 0.7242 - val_acc: 0.6675\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.5088 - acc: 0.7855 - val_loss: 0.7490 - val_acc: 0.6658\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2663 - acc: 0.8990 - val_loss: 0.9609 - val_acc: 0.6582\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1167 - acc: 0.9633 - val_loss: 1.2378 - val_acc: 0.6574\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0657 - acc: 0.9818 - val_loss: 1.4377 - val_acc: 0.6540\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0483 - acc: 0.9879 - val_loss: 1.5463 - val_acc: 0.6582\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0385 - acc: 0.9913 - val_loss: 1.7130 - val_acc: 0.6439\n",
      "Training with combination number 70/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 28s 3ms/step - loss: 0.8211 - acc: 0.6030 - val_loss: 0.7250 - val_acc: 0.6684\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.5077 - acc: 0.7877 - val_loss: 0.7474 - val_acc: 0.6802\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2624 - acc: 0.9004 - val_loss: 0.9724 - val_acc: 0.6650\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1051 - acc: 0.9666 - val_loss: 1.2090 - val_acc: 0.6599\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0661 - acc: 0.9808 - val_loss: 1.4118 - val_acc: 0.6557\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0487 - acc: 0.9875 - val_loss: 1.5145 - val_acc: 0.6717\n",
      "Epoch 7/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0404 - acc: 0.9903 - val_loss: 1.6103 - val_acc: 0.6667\n",
      "Training with combination number 71/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 28s 3ms/step - loss: 0.8202 - acc: 0.6033 - val_loss: 0.7181 - val_acc: 0.6591\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.5083 - acc: 0.7902 - val_loss: 0.7581 - val_acc: 0.6641\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2641 - acc: 0.9042 - val_loss: 0.9131 - val_acc: 0.6608\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1123 - acc: 0.9640 - val_loss: 1.1996 - val_acc: 0.6565\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0607 - acc: 0.9833 - val_loss: 1.4423 - val_acc: 0.6557\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0456 - acc: 0.9875 - val_loss: 1.5584 - val_acc: 0.6481\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0356 - acc: 0.9909 - val_loss: 1.5858 - val_acc: 0.6489\n",
      "Training with combination number 72/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 29s 3ms/step - loss: 0.8159 - acc: 0.6113 - val_loss: 0.7116 - val_acc: 0.6641\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.5144 - acc: 0.7836 - val_loss: 0.7446 - val_acc: 0.6743\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2680 - acc: 0.8983 - val_loss: 0.9232 - val_acc: 0.6650\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1227 - acc: 0.9599 - val_loss: 1.1866 - val_acc: 0.6633\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0668 - acc: 0.9831 - val_loss: 1.3744 - val_acc: 0.6489\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0463 - acc: 0.9874 - val_loss: 1.5690 - val_acc: 0.6557\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0372 - acc: 0.9905 - val_loss: 1.5656 - val_acc: 0.6498\n",
      "Training with combination number 73/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 28s 3ms/step - loss: 0.8135 - acc: 0.6102 - val_loss: 0.7188 - val_acc: 0.6591\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.5153 - acc: 0.7868 - val_loss: 0.7443 - val_acc: 0.6633\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2632 - acc: 0.9022 - val_loss: 0.8958 - val_acc: 0.6692\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1148 - acc: 0.9629 - val_loss: 1.1700 - val_acc: 0.6675\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0646 - acc: 0.9803 - val_loss: 1.4383 - val_acc: 0.6616\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0463 - acc: 0.9881 - val_loss: 1.5484 - val_acc: 0.6388\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0382 - acc: 0.9899 - val_loss: 1.6260 - val_acc: 0.6540\n",
      "Training with combination number 74/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 28s 3ms/step - loss: 0.8162 - acc: 0.6093 - val_loss: 0.7174 - val_acc: 0.6506\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.5085 - acc: 0.7891 - val_loss: 0.7437 - val_acc: 0.6819\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2728 - acc: 0.8992 - val_loss: 0.8966 - val_acc: 0.6684\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1231 - acc: 0.9616 - val_loss: 1.1823 - val_acc: 0.6658\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0637 - acc: 0.9802 - val_loss: 1.4181 - val_acc: 0.6565\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0435 - acc: 0.9881 - val_loss: 1.5868 - val_acc: 0.6709\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0371 - acc: 0.9909 - val_loss: 1.6239 - val_acc: 0.6751\n",
      "Training with combination number 75/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 28s 3ms/step - loss: 0.8190 - acc: 0.6086 - val_loss: 0.7127 - val_acc: 0.6624\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.5139 - acc: 0.7862 - val_loss: 0.7548 - val_acc: 0.6684\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2663 - acc: 0.9023 - val_loss: 0.9076 - val_acc: 0.6802\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1138 - acc: 0.9631 - val_loss: 1.1392 - val_acc: 0.6667\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0720 - acc: 0.9825 - val_loss: 1.3524 - val_acc: 0.6380\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0433 - acc: 0.9884 - val_loss: 1.4952 - val_acc: 0.6717\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0377 - acc: 0.9907 - val_loss: 1.5236 - val_acc: 0.6599\n",
      "Training with combination number 76/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 29s 3ms/step - loss: 0.8236 - acc: 0.6006 - val_loss: 0.7397 - val_acc: 0.6658\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 27s 3ms/step - loss: 0.5152 - acc: 0.7836 - val_loss: 0.7459 - val_acc: 0.6734\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.2697 - acc: 0.8999 - val_loss: 0.9640 - val_acc: 0.6667\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.1220 - acc: 0.9593 - val_loss: 1.2070 - val_acc: 0.6540\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0649 - acc: 0.9817 - val_loss: 1.4492 - val_acc: 0.6447\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0460 - acc: 0.9885 - val_loss: 1.5911 - val_acc: 0.6481\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0423 - acc: 0.9889 - val_loss: 1.6320 - val_acc: 0.6540\n",
      "Training with combination number 77/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 29s 3ms/step - loss: 0.8237 - acc: 0.6054 - val_loss: 0.7181 - val_acc: 0.6641\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.5179 - acc: 0.7884 - val_loss: 0.7489 - val_acc: 0.6700\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.2690 - acc: 0.8994 - val_loss: 0.9554 - val_acc: 0.6650\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1158 - acc: 0.9615 - val_loss: 1.1942 - val_acc: 0.6591\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0639 - acc: 0.9823 - val_loss: 1.4512 - val_acc: 0.6616\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0462 - acc: 0.9878 - val_loss: 1.5336 - val_acc: 0.6430\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0336 - acc: 0.9920 - val_loss: 1.5918 - val_acc: 0.6557\n",
      "Training with combination number 78/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 28s 3ms/step - loss: 0.8214 - acc: 0.6087 - val_loss: 0.7201 - val_acc: 0.6709\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.5133 - acc: 0.7838 - val_loss: 0.7646 - val_acc: 0.6776\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2649 - acc: 0.9009 - val_loss: 0.9590 - val_acc: 0.6599\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1130 - acc: 0.9634 - val_loss: 1.2121 - val_acc: 0.6726\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0573 - acc: 0.9848 - val_loss: 1.4359 - val_acc: 0.6633\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0554 - acc: 0.9855 - val_loss: 1.5111 - val_acc: 0.6624\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0437 - acc: 0.9895 - val_loss: 1.5938 - val_acc: 0.6667\n",
      "Training with combination number 79/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 28s 3ms/step - loss: 0.8193 - acc: 0.6083 - val_loss: 0.7123 - val_acc: 0.6717\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.5078 - acc: 0.7914 - val_loss: 0.7587 - val_acc: 0.6785\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.2588 - acc: 0.9018 - val_loss: 0.9820 - val_acc: 0.6591\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1196 - acc: 0.9618 - val_loss: 1.2147 - val_acc: 0.6506\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0587 - acc: 0.9827 - val_loss: 1.4010 - val_acc: 0.6532\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0409 - acc: 0.9888 - val_loss: 1.5460 - val_acc: 0.6667\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0401 - acc: 0.9908 - val_loss: 1.6427 - val_acc: 0.6633\n",
      "Training with combination number 80/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 29s 3ms/step - loss: 0.8384 - acc: 0.5970 - val_loss: 0.7498 - val_acc: 0.6414\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 27s 2ms/step - loss: 0.5059 - acc: 0.7892 - val_loss: 0.7825 - val_acc: 0.6684\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.2396 - acc: 0.9117 - val_loss: 1.0458 - val_acc: 0.6608\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.1068 - acc: 0.9658 - val_loss: 1.3387 - val_acc: 0.6464\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0593 - acc: 0.9828 - val_loss: 1.5108 - val_acc: 0.6574\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0449 - acc: 0.9893 - val_loss: 1.6404 - val_acc: 0.6422\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0369 - acc: 0.9900 - val_loss: 1.7326 - val_acc: 0.6532\n",
      "Training with combination number 81/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 28s 3ms/step - loss: 0.8365 - acc: 0.5946 - val_loss: 0.7458 - val_acc: 0.6532\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.5064 - acc: 0.7899 - val_loss: 0.8038 - val_acc: 0.6641\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2393 - acc: 0.9122 - val_loss: 1.0727 - val_acc: 0.6346\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1095 - acc: 0.9652 - val_loss: 1.3421 - val_acc: 0.6489\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0574 - acc: 0.9853 - val_loss: 1.5290 - val_acc: 0.6388\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0416 - acc: 0.9883 - val_loss: 1.6794 - val_acc: 0.6456\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0338 - acc: 0.9917 - val_loss: 1.7777 - val_acc: 0.6363\n",
      "Training with combination number 82/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 28s 3ms/step - loss: 0.8339 - acc: 0.5959 - val_loss: 0.7511 - val_acc: 0.6456\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.5003 - acc: 0.7948 - val_loss: 0.7862 - val_acc: 0.6540\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2447 - acc: 0.9118 - val_loss: 1.0072 - val_acc: 0.6456\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.1013 - acc: 0.9678 - val_loss: 1.4221 - val_acc: 0.6405\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0627 - acc: 0.9840 - val_loss: 1.4647 - val_acc: 0.6608\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0439 - acc: 0.9872 - val_loss: 1.6519 - val_acc: 0.6574\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0325 - acc: 0.9919 - val_loss: 1.7190 - val_acc: 0.6456\n",
      "Training with combination number 83/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 28s 3ms/step - loss: 0.8305 - acc: 0.5937 - val_loss: 0.7653 - val_acc: 0.6439\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.5023 - acc: 0.7941 - val_loss: 0.7977 - val_acc: 0.6616\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2438 - acc: 0.9080 - val_loss: 1.0185 - val_acc: 0.6447\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.1067 - acc: 0.9672 - val_loss: 1.3212 - val_acc: 0.6523\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0588 - acc: 0.9849 - val_loss: 1.4621 - val_acc: 0.6481\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0405 - acc: 0.9895 - val_loss: 1.6501 - val_acc: 0.6422\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0323 - acc: 0.9917 - val_loss: 1.7253 - val_acc: 0.6540\n",
      "Training with combination number 84/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 29s 3ms/step - loss: 0.8446 - acc: 0.5899 - val_loss: 0.7672 - val_acc: 0.6456\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.5003 - acc: 0.7895 - val_loss: 0.7990 - val_acc: 0.6624\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.2427 - acc: 0.9116 - val_loss: 1.0485 - val_acc: 0.6515\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.1031 - acc: 0.9686 - val_loss: 1.4098 - val_acc: 0.6338\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0584 - acc: 0.9837 - val_loss: 1.5782 - val_acc: 0.6473\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0373 - acc: 0.9903 - val_loss: 1.7501 - val_acc: 0.6456\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0362 - acc: 0.9913 - val_loss: 1.7909 - val_acc: 0.6363\n",
      "Training with combination number 85/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 29s 3ms/step - loss: 0.8420 - acc: 0.5923 - val_loss: 0.7517 - val_acc: 0.6557\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.4997 - acc: 0.7931 - val_loss: 0.7982 - val_acc: 0.6574\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2491 - acc: 0.9086 - val_loss: 1.0500 - val_acc: 0.6464\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1145 - acc: 0.9619 - val_loss: 1.3457 - val_acc: 0.6405\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0598 - acc: 0.9822 - val_loss: 1.5370 - val_acc: 0.6506\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0366 - acc: 0.9892 - val_loss: 1.8183 - val_acc: 0.6270\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0360 - acc: 0.9907 - val_loss: 1.9266 - val_acc: 0.6186\n",
      "Training with combination number 86/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 28s 3ms/step - loss: 0.8428 - acc: 0.5920 - val_loss: 0.7723 - val_acc: 0.6447\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.5011 - acc: 0.7917 - val_loss: 0.7916 - val_acc: 0.6633\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.2440 - acc: 0.9109 - val_loss: 1.0711 - val_acc: 0.6312\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1065 - acc: 0.9660 - val_loss: 1.3794 - val_acc: 0.6515\n",
      "Epoch 5/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0524 - acc: 0.9853 - val_loss: 1.7074 - val_acc: 0.6515\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0400 - acc: 0.9896 - val_loss: 1.7642 - val_acc: 0.6582\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0328 - acc: 0.9916 - val_loss: 1.8957 - val_acc: 0.6388\n",
      "Training with combination number 87/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 28s 3ms/step - loss: 0.8397 - acc: 0.5905 - val_loss: 0.7544 - val_acc: 0.6565\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.4952 - acc: 0.7932 - val_loss: 0.7878 - val_acc: 0.6574\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2461 - acc: 0.9107 - val_loss: 1.0536 - val_acc: 0.6363\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1059 - acc: 0.9664 - val_loss: 1.3238 - val_acc: 0.6565\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0563 - acc: 0.9842 - val_loss: 1.5581 - val_acc: 0.6582\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0414 - acc: 0.9891 - val_loss: 1.6489 - val_acc: 0.6473\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0307 - acc: 0.9930 - val_loss: 1.8481 - val_acc: 0.6253\n",
      "Training with combination number 88/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 29s 3ms/step - loss: 0.8417 - acc: 0.5935 - val_loss: 0.7455 - val_acc: 0.6532\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.5019 - acc: 0.7889 - val_loss: 0.8192 - val_acc: 0.6599\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.2499 - acc: 0.9044 - val_loss: 0.9904 - val_acc: 0.6709\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1043 - acc: 0.9658 - val_loss: 1.3543 - val_acc: 0.6422\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0582 - acc: 0.9816 - val_loss: 1.5365 - val_acc: 0.6616\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0430 - acc: 0.9894 - val_loss: 1.6100 - val_acc: 0.6523\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0379 - acc: 0.9903 - val_loss: 1.6248 - val_acc: 0.6582\n",
      "Training with combination number 89/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 28s 3ms/step - loss: 0.8429 - acc: 0.5914 - val_loss: 0.7619 - val_acc: 0.6489\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.4992 - acc: 0.7964 - val_loss: 0.8075 - val_acc: 0.6599\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2452 - acc: 0.9117 - val_loss: 1.0180 - val_acc: 0.6447\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1046 - acc: 0.9659 - val_loss: 1.3605 - val_acc: 0.6397\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0603 - acc: 0.9849 - val_loss: 1.5157 - val_acc: 0.6498\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0349 - acc: 0.9904 - val_loss: 1.6346 - val_acc: 0.6481\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0325 - acc: 0.9914 - val_loss: 1.7012 - val_acc: 0.6506\n",
      "Training with combination number 90/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 29s 3ms/step - loss: 0.8389 - acc: 0.5955 - val_loss: 0.7507 - val_acc: 0.6549\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.5017 - acc: 0.7903 - val_loss: 0.7887 - val_acc: 0.6591\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.2466 - acc: 0.9117 - val_loss: 1.0233 - val_acc: 0.6549\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1051 - acc: 0.9665 - val_loss: 1.3315 - val_acc: 0.6464\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0564 - acc: 0.9850 - val_loss: 1.5535 - val_acc: 0.6456\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0420 - acc: 0.9887 - val_loss: 1.6658 - val_acc: 0.6439\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0328 - acc: 0.9925 - val_loss: 1.7279 - val_acc: 0.6540\n",
      "Training with combination number 91/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 30s 3ms/step - loss: 0.8385 - acc: 0.5908 - val_loss: 0.7480 - val_acc: 0.6565\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.4992 - acc: 0.7935 - val_loss: 0.8153 - val_acc: 0.6473\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2475 - acc: 0.9096 - val_loss: 1.0218 - val_acc: 0.6456\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1015 - acc: 0.9682 - val_loss: 1.3503 - val_acc: 0.6574\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0611 - acc: 0.9842 - val_loss: 1.5318 - val_acc: 0.6498\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0481 - acc: 0.9888 - val_loss: 1.6138 - val_acc: 0.6430\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0375 - acc: 0.9909 - val_loss: 1.7996 - val_acc: 0.6633\n",
      "Training with combination number 92/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 32s 3ms/step - loss: 0.8449 - acc: 0.5902 - val_loss: 0.7605 - val_acc: 0.6549\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.5034 - acc: 0.7971 - val_loss: 0.8256 - val_acc: 0.6498\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2407 - acc: 0.9098 - val_loss: 1.0597 - val_acc: 0.6473\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1041 - acc: 0.9670 - val_loss: 1.3691 - val_acc: 0.6388\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0584 - acc: 0.9843 - val_loss: 1.5867 - val_acc: 0.6397\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0470 - acc: 0.9887 - val_loss: 1.6690 - val_acc: 0.6414\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0321 - acc: 0.9917 - val_loss: 1.8623 - val_acc: 0.6430\n",
      "Training with combination number 93/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 31s 3ms/step - loss: 0.8361 - acc: 0.5950 - val_loss: 0.7532 - val_acc: 0.6633\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.4979 - acc: 0.7962 - val_loss: 0.8104 - val_acc: 0.6447\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2458 - acc: 0.9115 - val_loss: 1.0136 - val_acc: 0.6489\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1103 - acc: 0.9649 - val_loss: 1.3208 - val_acc: 0.6523\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0549 - acc: 0.9850 - val_loss: 1.6297 - val_acc: 0.6388\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0346 - acc: 0.9914 - val_loss: 1.7811 - val_acc: 0.6523\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0307 - acc: 0.9917 - val_loss: 1.9024 - val_acc: 0.6371\n",
      "Training with combination number 94/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 31s 3ms/step - loss: 0.8386 - acc: 0.5960 - val_loss: 0.7522 - val_acc: 0.6464\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.4920 - acc: 0.7982 - val_loss: 0.8050 - val_acc: 0.6574\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.2411 - acc: 0.9115 - val_loss: 1.0046 - val_acc: 0.6624\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.1007 - acc: 0.9676 - val_loss: 1.3423 - val_acc: 0.6464\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0597 - acc: 0.9841 - val_loss: 1.5702 - val_acc: 0.6565\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0401 - acc: 0.9887 - val_loss: 1.6617 - val_acc: 0.6515\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0299 - acc: 0.9919 - val_loss: 1.7858 - val_acc: 0.6591\n",
      "Training with combination number 95/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 29s 3ms/step - loss: 0.8349 - acc: 0.5989 - val_loss: 0.7523 - val_acc: 0.6523\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.4905 - acc: 0.7982 - val_loss: 0.8299 - val_acc: 0.6506\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.2333 - acc: 0.9131 - val_loss: 1.0731 - val_acc: 0.6439\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 27s 2ms/step - loss: 0.1024 - acc: 0.9682 - val_loss: 1.3973 - val_acc: 0.6414\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0585 - acc: 0.9842 - val_loss: 1.6293 - val_acc: 0.6414\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0412 - acc: 0.9902 - val_loss: 1.7405 - val_acc: 0.6456\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0325 - acc: 0.9920 - val_loss: 1.8891 - val_acc: 0.6262\n",
      "Training with combination number 96/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 29s 3ms/step - loss: 0.8274 - acc: 0.6041 - val_loss: 0.7260 - val_acc: 0.6582\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.5420 - acc: 0.7745 - val_loss: 0.7648 - val_acc: 0.6481\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.3106 - acc: 0.8807 - val_loss: 0.9025 - val_acc: 0.6464\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.1360 - acc: 0.9554 - val_loss: 1.1789 - val_acc: 0.6388\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0857 - acc: 0.9746 - val_loss: 1.3340 - val_acc: 0.6549\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0507 - acc: 0.9867 - val_loss: 1.5261 - val_acc: 0.6464\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0408 - acc: 0.9887 - val_loss: 1.6684 - val_acc: 0.6574\n",
      "Training with combination number 97/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 29s 3ms/step - loss: 0.8210 - acc: 0.6053 - val_loss: 0.7253 - val_acc: 0.6549\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.5431 - acc: 0.7714 - val_loss: 0.7836 - val_acc: 0.6422\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.2982 - acc: 0.8867 - val_loss: 0.9308 - val_acc: 0.6338\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.1345 - acc: 0.9534 - val_loss: 1.2096 - val_acc: 0.6456\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0802 - acc: 0.9745 - val_loss: 1.3691 - val_acc: 0.6608\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0576 - acc: 0.9849 - val_loss: 1.5322 - val_acc: 0.6540\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0420 - acc: 0.9891 - val_loss: 1.5806 - val_acc: 0.6422\n",
      "Training with combination number 98/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 29s 3ms/step - loss: 0.8266 - acc: 0.6026 - val_loss: 0.7207 - val_acc: 0.6641\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.5381 - acc: 0.7746 - val_loss: 0.7539 - val_acc: 0.6667\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.3009 - acc: 0.8890 - val_loss: 0.9049 - val_acc: 0.6515\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1428 - acc: 0.9536 - val_loss: 1.1105 - val_acc: 0.6506\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0747 - acc: 0.9777 - val_loss: 1.3654 - val_acc: 0.6430\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0452 - acc: 0.9871 - val_loss: 1.5244 - val_acc: 0.6549\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0454 - acc: 0.9887 - val_loss: 1.5996 - val_acc: 0.6498\n",
      "Training with combination number 99/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 29s 3ms/step - loss: 0.8254 - acc: 0.6004 - val_loss: 0.7233 - val_acc: 0.6692\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.5402 - acc: 0.7762 - val_loss: 0.7614 - val_acc: 0.6574\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.3009 - acc: 0.8874 - val_loss: 0.9168 - val_acc: 0.6346\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.1371 - acc: 0.9540 - val_loss: 1.1701 - val_acc: 0.6540\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0816 - acc: 0.9766 - val_loss: 1.4174 - val_acc: 0.6422\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0496 - acc: 0.9862 - val_loss: 1.5556 - val_acc: 0.6346\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 27s 2ms/step - loss: 0.0464 - acc: 0.9861 - val_loss: 1.6125 - val_acc: 0.6506\n",
      "Training with combination number 100/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 29s 3ms/step - loss: 0.8333 - acc: 0.5999 - val_loss: 0.7359 - val_acc: 0.6532\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.5408 - acc: 0.7709 - val_loss: 0.7651 - val_acc: 0.6616\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2929 - acc: 0.8876 - val_loss: 1.0115 - val_acc: 0.6473\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.1377 - acc: 0.9556 - val_loss: 1.2276 - val_acc: 0.6304\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0718 - acc: 0.9790 - val_loss: 1.4429 - val_acc: 0.6194\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0533 - acc: 0.9859 - val_loss: 1.5539 - val_acc: 0.6228\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0333 - acc: 0.9915 - val_loss: 1.7214 - val_acc: 0.6253\n",
      "Training with combination number 101/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 29s 3ms/step - loss: 0.8262 - acc: 0.5988 - val_loss: 0.7435 - val_acc: 0.6515\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.5388 - acc: 0.7726 - val_loss: 0.7671 - val_acc: 0.6506\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2915 - acc: 0.8906 - val_loss: 0.9270 - val_acc: 0.6219\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1357 - acc: 0.9563 - val_loss: 1.2515 - val_acc: 0.6346\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0667 - acc: 0.9790 - val_loss: 1.5169 - val_acc: 0.6346\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0519 - acc: 0.9865 - val_loss: 1.5661 - val_acc: 0.6287\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0389 - acc: 0.9889 - val_loss: 1.6921 - val_acc: 0.6312\n",
      "Training with combination number 102/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 29s 3ms/step - loss: 0.8296 - acc: 0.6047 - val_loss: 0.7383 - val_acc: 0.6633\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.5263 - acc: 0.7803 - val_loss: 0.7869 - val_acc: 0.6506\n",
      "Epoch 3/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2865 - acc: 0.8909 - val_loss: 0.9116 - val_acc: 0.6515\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1289 - acc: 0.9579 - val_loss: 1.1961 - val_acc: 0.6346\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0718 - acc: 0.9800 - val_loss: 1.3888 - val_acc: 0.6464\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0495 - acc: 0.9862 - val_loss: 1.4944 - val_acc: 0.6515\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0426 - acc: 0.9868 - val_loss: 1.6945 - val_acc: 0.6498\n",
      "Training with combination number 103/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 30s 3ms/step - loss: 0.8260 - acc: 0.6062 - val_loss: 0.7427 - val_acc: 0.6549\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 27s 3ms/step - loss: 0.5345 - acc: 0.7733 - val_loss: 0.7825 - val_acc: 0.6532\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 27s 2ms/step - loss: 0.2896 - acc: 0.8908 - val_loss: 0.9228 - val_acc: 0.6515\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.1303 - acc: 0.9572 - val_loss: 1.2275 - val_acc: 0.6557\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0738 - acc: 0.9782 - val_loss: 1.3640 - val_acc: 0.6414\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0467 - acc: 0.9873 - val_loss: 1.5659 - val_acc: 0.6397\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0332 - acc: 0.9902 - val_loss: 1.6933 - val_acc: 0.6439\n",
      "Training with combination number 104/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 29s 3ms/step - loss: 0.8258 - acc: 0.6086 - val_loss: 0.7333 - val_acc: 0.6591\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.5400 - acc: 0.7724 - val_loss: 0.7448 - val_acc: 0.6565\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.2918 - acc: 0.8898 - val_loss: 0.9448 - val_acc: 0.6624\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1366 - acc: 0.9555 - val_loss: 1.1402 - val_acc: 0.6481\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0701 - acc: 0.9793 - val_loss: 1.4497 - val_acc: 0.6405\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0477 - acc: 0.9860 - val_loss: 1.5093 - val_acc: 0.6726\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0432 - acc: 0.9883 - val_loss: 1.5835 - val_acc: 0.6371\n",
      "Training with combination number 105/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 29s 3ms/step - loss: 0.8281 - acc: 0.6043 - val_loss: 0.7290 - val_acc: 0.6574\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.5471 - acc: 0.7676 - val_loss: 0.7581 - val_acc: 0.6506\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.3028 - acc: 0.8876 - val_loss: 0.9171 - val_acc: 0.6464\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1386 - acc: 0.9543 - val_loss: 1.1819 - val_acc: 0.6473\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0793 - acc: 0.9742 - val_loss: 1.3878 - val_acc: 0.6371\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0522 - acc: 0.9869 - val_loss: 1.4834 - val_acc: 0.6397\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0362 - acc: 0.9901 - val_loss: 1.6326 - val_acc: 0.6422\n",
      "Training with combination number 106/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 29s 3ms/step - loss: 0.8239 - acc: 0.6061 - val_loss: 0.7292 - val_acc: 0.6498\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.5380 - acc: 0.7782 - val_loss: 0.7792 - val_acc: 0.6633\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.3002 - acc: 0.8866 - val_loss: 0.9161 - val_acc: 0.6574\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.1374 - acc: 0.9550 - val_loss: 1.1919 - val_acc: 0.6397\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0745 - acc: 0.9777 - val_loss: 1.3418 - val_acc: 0.6506\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0530 - acc: 0.9855 - val_loss: 1.5142 - val_acc: 0.6515\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0393 - acc: 0.9891 - val_loss: 1.6114 - val_acc: 0.6582\n",
      "Training with combination number 107/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 30s 3ms/step - loss: 0.8249 - acc: 0.6021 - val_loss: 0.7351 - val_acc: 0.6549\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.5460 - acc: 0.7684 - val_loss: 0.7349 - val_acc: 0.6574\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.2982 - acc: 0.8863 - val_loss: 0.9352 - val_acc: 0.6473\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.1383 - acc: 0.9534 - val_loss: 1.1662 - val_acc: 0.6481\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0737 - acc: 0.9775 - val_loss: 1.3556 - val_acc: 0.6481\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0570 - acc: 0.9826 - val_loss: 1.4655 - val_acc: 0.6414\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0435 - acc: 0.9896 - val_loss: 1.5800 - val_acc: 0.6515\n",
      "Training with combination number 108/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 29s 3ms/step - loss: 0.8318 - acc: 0.6019 - val_loss: 0.7387 - val_acc: 0.6667\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.5375 - acc: 0.7735 - val_loss: 0.7789 - val_acc: 0.6388\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2988 - acc: 0.8891 - val_loss: 0.9749 - val_acc: 0.6489\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1365 - acc: 0.9541 - val_loss: 1.1866 - val_acc: 0.6278\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0747 - acc: 0.9794 - val_loss: 1.4428 - val_acc: 0.6388\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0528 - acc: 0.9853 - val_loss: 1.5837 - val_acc: 0.6363\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0352 - acc: 0.9910 - val_loss: 1.7032 - val_acc: 0.6371\n",
      "Training with combination number 109/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 29s 3ms/step - loss: 0.8322 - acc: 0.5999 - val_loss: 0.7396 - val_acc: 0.6599\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.5412 - acc: 0.7755 - val_loss: 0.7627 - val_acc: 0.6523\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2912 - acc: 0.8868 - val_loss: 0.9477 - val_acc: 0.6506\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.1302 - acc: 0.9563 - val_loss: 1.1376 - val_acc: 0.6540\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0754 - acc: 0.9809 - val_loss: 1.4255 - val_acc: 0.6464\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0545 - acc: 0.9837 - val_loss: 1.5419 - val_acc: 0.6439\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0409 - acc: 0.9890 - val_loss: 1.6549 - val_acc: 0.6473\n",
      "Training with combination number 110/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 30s 3ms/step - loss: 0.8265 - acc: 0.6054 - val_loss: 0.7346 - val_acc: 0.6641\n",
      "Epoch 2/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.5356 - acc: 0.7758 - val_loss: 0.7879 - val_acc: 0.6616\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.2903 - acc: 0.8891 - val_loss: 0.9429 - val_acc: 0.6464\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.1340 - acc: 0.9546 - val_loss: 1.2232 - val_acc: 0.6473\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0657 - acc: 0.9808 - val_loss: 1.4893 - val_acc: 0.6388\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0518 - acc: 0.9844 - val_loss: 1.5571 - val_acc: 0.6447\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 27s 3ms/step - loss: 0.0415 - acc: 0.9882 - val_loss: 1.6182 - val_acc: 0.6380\n",
      "Training with combination number 111/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 31s 3ms/step - loss: 0.8320 - acc: 0.5958 - val_loss: 0.7556 - val_acc: 0.6414\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 27s 3ms/step - loss: 0.5375 - acc: 0.7723 - val_loss: 0.7711 - val_acc: 0.6650\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 27s 3ms/step - loss: 0.2940 - acc: 0.8883 - val_loss: 0.9243 - val_acc: 0.6557\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.1337 - acc: 0.9575 - val_loss: 1.1810 - val_acc: 0.6456\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0777 - acc: 0.9774 - val_loss: 1.4494 - val_acc: 0.6430\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0483 - acc: 0.9870 - val_loss: 1.6306 - val_acc: 0.6447\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0371 - acc: 0.9900 - val_loss: 1.6973 - val_acc: 0.6338\n",
      "Training with combination number 112/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 30s 3ms/step - loss: 0.8451 - acc: 0.5947 - val_loss: 0.7658 - val_acc: 0.6557\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.5310 - acc: 0.7840 - val_loss: 0.8359 - val_acc: 0.6363\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.2704 - acc: 0.8974 - val_loss: 1.0596 - val_acc: 0.6169\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.1205 - acc: 0.9607 - val_loss: 1.3729 - val_acc: 0.6228\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0668 - acc: 0.9784 - val_loss: 1.5392 - val_acc: 0.6338\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0458 - acc: 0.9876 - val_loss: 1.6945 - val_acc: 0.6287\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0372 - acc: 0.9906 - val_loss: 1.7897 - val_acc: 0.6203\n",
      "Training with combination number 113/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 30s 3ms/step - loss: 0.8477 - acc: 0.5940 - val_loss: 0.7690 - val_acc: 0.6506\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.5374 - acc: 0.7735 - val_loss: 0.8163 - val_acc: 0.6430\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.2748 - acc: 0.8993 - val_loss: 1.0389 - val_acc: 0.6371\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.1241 - acc: 0.9599 - val_loss: 1.2928 - val_acc: 0.6422\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0598 - acc: 0.9823 - val_loss: 1.5457 - val_acc: 0.6371\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0471 - acc: 0.9879 - val_loss: 1.6638 - val_acc: 0.6295\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0308 - acc: 0.9909 - val_loss: 1.8330 - val_acc: 0.6354\n",
      "Training with combination number 114/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 30s 3ms/step - loss: 0.8411 - acc: 0.5991 - val_loss: 0.7627 - val_acc: 0.6422\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.5327 - acc: 0.7774 - val_loss: 0.8299 - val_acc: 0.6405\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.2728 - acc: 0.8988 - val_loss: 1.0364 - val_acc: 0.6329\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.1244 - acc: 0.9596 - val_loss: 1.2953 - val_acc: 0.6338\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 27s 3ms/step - loss: 0.0672 - acc: 0.9791 - val_loss: 1.5642 - val_acc: 0.6186\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 27s 3ms/step - loss: 0.0401 - acc: 0.9884 - val_loss: 1.7454 - val_acc: 0.6270\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 27s 3ms/step - loss: 0.0310 - acc: 0.9917 - val_loss: 1.8218 - val_acc: 0.6253\n",
      "Training with combination number 115/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 31s 3ms/step - loss: 0.8394 - acc: 0.5958 - val_loss: 0.7827 - val_acc: 0.6287\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.5308 - acc: 0.7783 - val_loss: 0.8340 - val_acc: 0.6304\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.2740 - acc: 0.8972 - val_loss: 1.0326 - val_acc: 0.6354\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.1167 - acc: 0.9631 - val_loss: 1.3463 - val_acc: 0.6236\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0608 - acc: 0.9850 - val_loss: 1.5562 - val_acc: 0.6278\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0524 - acc: 0.9862 - val_loss: 1.5984 - val_acc: 0.6287\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0351 - acc: 0.9900 - val_loss: 1.7673 - val_acc: 0.6354\n",
      "Training with combination number 116/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 30s 3ms/step - loss: 0.8536 - acc: 0.5830 - val_loss: 0.7823 - val_acc: 0.6405\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.5308 - acc: 0.7792 - val_loss: 0.8330 - val_acc: 0.6278\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.2691 - acc: 0.8994 - val_loss: 1.1008 - val_acc: 0.6278\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.1174 - acc: 0.9592 - val_loss: 1.4230 - val_acc: 0.6245\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0675 - acc: 0.9808 - val_loss: 1.6418 - val_acc: 0.6211\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0457 - acc: 0.9882 - val_loss: 1.8491 - val_acc: 0.6270\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0358 - acc: 0.9902 - val_loss: 1.8973 - val_acc: 0.6270\n",
      "Training with combination number 117/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 30s 3ms/step - loss: 0.8539 - acc: 0.5864 - val_loss: 0.7904 - val_acc: 0.6304\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.5277 - acc: 0.7791 - val_loss: 0.8542 - val_acc: 0.6262\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.2653 - acc: 0.9030 - val_loss: 1.1420 - val_acc: 0.6186\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.1182 - acc: 0.9623 - val_loss: 1.4524 - val_acc: 0.6118\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0653 - acc: 0.9798 - val_loss: 1.6219 - val_acc: 0.6228\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0382 - acc: 0.9892 - val_loss: 1.8734 - val_acc: 0.6194\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0309 - acc: 0.9922 - val_loss: 2.0155 - val_acc: 0.6211\n",
      "Training with combination number 118/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 30s 3ms/step - loss: 0.8500 - acc: 0.5903 - val_loss: 0.7773 - val_acc: 0.6498\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.5313 - acc: 0.7813 - val_loss: 0.8351 - val_acc: 0.6481\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.2615 - acc: 0.9037 - val_loss: 1.1012 - val_acc: 0.6203\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 27s 3ms/step - loss: 0.1147 - acc: 0.9627 - val_loss: 1.3982 - val_acc: 0.6329\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 27s 3ms/step - loss: 0.0611 - acc: 0.9820 - val_loss: 1.6733 - val_acc: 0.6228\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 27s 3ms/step - loss: 0.0442 - acc: 0.9878 - val_loss: 1.8329 - val_acc: 0.6295\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 27s 3ms/step - loss: 0.0386 - acc: 0.9890 - val_loss: 1.9173 - val_acc: 0.6169\n",
      "Training with combination number 119/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 30s 3ms/step - loss: 0.8482 - acc: 0.5886 - val_loss: 0.7837 - val_acc: 0.6464\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.5325 - acc: 0.7789 - val_loss: 0.8156 - val_acc: 0.6321\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.2746 - acc: 0.8971 - val_loss: 1.0747 - val_acc: 0.6059\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.1205 - acc: 0.9592 - val_loss: 1.3936 - val_acc: 0.6304\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0657 - acc: 0.9811 - val_loss: 1.6169 - val_acc: 0.6118\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0542 - acc: 0.9879 - val_loss: 1.7053 - val_acc: 0.6253\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0331 - acc: 0.9920 - val_loss: 1.8828 - val_acc: 0.6228\n",
      "Training with combination number 120/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 30s 3ms/step - loss: 0.8448 - acc: 0.5949 - val_loss: 0.7925 - val_acc: 0.6312\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.5321 - acc: 0.7784 - val_loss: 0.8227 - val_acc: 0.6321\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.2761 - acc: 0.8970 - val_loss: 1.0165 - val_acc: 0.6354\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.1243 - acc: 0.9601 - val_loss: 1.2851 - val_acc: 0.6456\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0678 - acc: 0.9794 - val_loss: 1.5285 - val_acc: 0.6321\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0492 - acc: 0.9878 - val_loss: 1.6589 - val_acc: 0.6329\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0387 - acc: 0.9907 - val_loss: 1.7442 - val_acc: 0.6354\n",
      "Training with combination number 121/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 30s 3ms/step - loss: 0.8448 - acc: 0.5934 - val_loss: 0.7716 - val_acc: 0.6338\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.5342 - acc: 0.7812 - val_loss: 0.8319 - val_acc: 0.6473\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.2699 - acc: 0.8982 - val_loss: 1.0759 - val_acc: 0.6329\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.1198 - acc: 0.9602 - val_loss: 1.3874 - val_acc: 0.6194\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0644 - acc: 0.9809 - val_loss: 1.5894 - val_acc: 0.6270\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0428 - acc: 0.9882 - val_loss: 1.7296 - val_acc: 0.6262\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0340 - acc: 0.9903 - val_loss: 1.8852 - val_acc: 0.6371\n",
      "Training with combination number 122/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 31s 3ms/step - loss: 0.8466 - acc: 0.5903 - val_loss: 0.7678 - val_acc: 0.6439\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 27s 3ms/step - loss: 0.5338 - acc: 0.7803 - val_loss: 0.8160 - val_acc: 0.6532\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 27s 3ms/step - loss: 0.2669 - acc: 0.8997 - val_loss: 1.0884 - val_acc: 0.6473\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 27s 3ms/step - loss: 0.1174 - acc: 0.9630 - val_loss: 1.3869 - val_acc: 0.6321\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 27s 3ms/step - loss: 0.0576 - acc: 0.9820 - val_loss: 1.5878 - val_acc: 0.6363\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 27s 2ms/step - loss: 0.0420 - acc: 0.9870 - val_loss: 1.8062 - val_acc: 0.6405\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0382 - acc: 0.9911 - val_loss: 1.7749 - val_acc: 0.6456\n",
      "Training with combination number 123/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 30s 3ms/step - loss: 0.8483 - acc: 0.5969 - val_loss: 0.7755 - val_acc: 0.6363\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.5295 - acc: 0.7796 - val_loss: 0.8338 - val_acc: 0.6456\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.2687 - acc: 0.9000 - val_loss: 1.0613 - val_acc: 0.6304\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.1210 - acc: 0.9601 - val_loss: 1.3138 - val_acc: 0.6236\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0622 - acc: 0.9821 - val_loss: 1.6386 - val_acc: 0.6304\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0410 - acc: 0.9885 - val_loss: 1.7523 - val_acc: 0.6338\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0348 - acc: 0.9909 - val_loss: 1.8845 - val_acc: 0.6084\n",
      "Training with combination number 124/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 33s 3ms/step - loss: 0.8555 - acc: 0.5858 - val_loss: 0.7758 - val_acc: 0.6439\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.5320 - acc: 0.7817 - val_loss: 0.8349 - val_acc: 0.6253\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.2752 - acc: 0.8950 - val_loss: 1.1423 - val_acc: 0.6110\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.1175 - acc: 0.9618 - val_loss: 1.3959 - val_acc: 0.6203\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0617 - acc: 0.9828 - val_loss: 1.6860 - val_acc: 0.5975\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0435 - acc: 0.9870 - val_loss: 1.8108 - val_acc: 0.6169\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0361 - acc: 0.9891 - val_loss: 1.9600 - val_acc: 0.6194\n",
      "Training with combination number 125/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 32s 3ms/step - loss: 0.8530 - acc: 0.5862 - val_loss: 0.7816 - val_acc: 0.6405\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 27s 2ms/step - loss: 0.5301 - acc: 0.7788 - val_loss: 0.8617 - val_acc: 0.6093\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.2650 - acc: 0.9034 - val_loss: 1.1183 - val_acc: 0.6177\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.1229 - acc: 0.9590 - val_loss: 1.4220 - val_acc: 0.6211\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0654 - acc: 0.9803 - val_loss: 1.6128 - val_acc: 0.6312\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0425 - acc: 0.9876 - val_loss: 1.7876 - val_acc: 0.6211\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0332 - acc: 0.9912 - val_loss: 1.9641 - val_acc: 0.6236\n",
      "Training with combination number 126/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 32s 3ms/step - loss: 0.8488 - acc: 0.5925 - val_loss: 0.7745 - val_acc: 0.6473\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 27s 3ms/step - loss: 0.5242 - acc: 0.7841 - val_loss: 0.8630 - val_acc: 0.6363\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 27s 3ms/step - loss: 0.2645 - acc: 0.9013 - val_loss: 1.0851 - val_acc: 0.6321\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 27s 3ms/step - loss: 0.1131 - acc: 0.9630 - val_loss: 1.4478 - val_acc: 0.6203\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0652 - acc: 0.9811 - val_loss: 1.6914 - val_acc: 0.6118\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0437 - acc: 0.9879 - val_loss: 1.8098 - val_acc: 0.6228\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0301 - acc: 0.9921 - val_loss: 1.9331 - val_acc: 0.6059\n",
      "Training with combination number 127/128\n",
      "Train on 10663 samples, validate on 1185 samples\n",
      "Epoch 1/7\n",
      "10663/10663 [==============================] - 30s 3ms/step - loss: 0.8509 - acc: 0.5915 - val_loss: 0.7901 - val_acc: 0.6262\n",
      "Epoch 2/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.5307 - acc: 0.7786 - val_loss: 0.8369 - val_acc: 0.6228\n",
      "Epoch 3/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.2666 - acc: 0.9029 - val_loss: 1.1115 - val_acc: 0.6287\n",
      "Epoch 4/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.1118 - acc: 0.9658 - val_loss: 1.4487 - val_acc: 0.6321\n",
      "Epoch 5/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0657 - acc: 0.9793 - val_loss: 1.5421 - val_acc: 0.6253\n",
      "Epoch 6/7\n",
      "10663/10663 [==============================] - 25s 2ms/step - loss: 0.0444 - acc: 0.9884 - val_loss: 1.7560 - val_acc: 0.6363\n",
      "Epoch 7/7\n",
      "10663/10663 [==============================] - 26s 2ms/step - loss: 0.0328 - acc: 0.9908 - val_loss: 1.8615 - val_acc: 0.6295\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "dl_exact_accuracies = []\n",
    "dl_precisions = []\n",
    "dl_recalls = []\n",
    "dl_f_measures = []\n",
    "N_WORDS = 10000\n",
    "gender_to_int = {'female':0,'male':1,'brand':2}\n",
    "int_to_gender = {0: 'female',1:'male',2:'brand'}\n",
    "for combination in combinations:\n",
    "    x_train_df = combination[0]\n",
    "    x_train = x_train_df['text_desc']\n",
    "    y_train = combination[0]['gender']\n",
    "    y_train = list([gender_to_int[gender] for gender in y_train]) \n",
    "    y_train = keras.utils.to_categorical(y_train, 3)\n",
    "    x_test_df = combination[1]\n",
    "    x_test = x_test_df['text_desc']\n",
    "    y_test = combination[1]['gender']\n",
    "    y_test = list([gender_to_int[gender] for gender in y_test]) \n",
    "#     y_test = keras.utils.to_categorical(y_test, 3)\n",
    "    tag = combination[2]\n",
    "\n",
    "    keras_tokenizer = kpt.Tokenizer(filters='',split = ' ',num_words=N_WORDS)#configuring the keras tokenizer to do close to nothing in terms of tokenization\n",
    "\n",
    "    texts_for_keras_tokenizer = list([' '.join(tokenizer.tokenize(text)) for text in x_train]) \n",
    "\n",
    "    keras_tokenizer.fit_on_texts(texts_for_keras_tokenizer)\n",
    "\n",
    "    x_train = keras_tokenizer.texts_to_matrix(texts_for_keras_tokenizer, mode='binary')\n",
    "\n",
    "\n",
    "    #todo optimize this\n",
    "    model = Sequential()#initialize the NN\n",
    "\n",
    "    #add a layer that gets N_WORDS inputs (this is the BOW representation of any tweet) and outputs 512 values ()\n",
    "    model.add(Dense(512, input_shape=(N_WORDS,), activation='relu'))\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "    model.add(Dense(3, activation='softmax'))# this gives a distribution over all 3 genders (probability of the input's belonging to any of the gender)\n",
    "    model.compile(loss='categorical_crossentropy',  optimizer='adam',  metrics=['accuracy']) \n",
    "    \n",
    "    \n",
    "    print('Training with combination number '+str(i)+'/'+str(len(combinations)))\n",
    "    \n",
    "    \n",
    "    details = '\\n\\nPreprocessing parameters:\\n'+tag\n",
    "    \n",
    "\n",
    "    t0 = time()\n",
    "    model.fit(x_train, y_train,  batch_size=32,  epochs=7,  verbose=1,  validation_split=0.1,  shuffle=True)\n",
    "    train_time = time() - t0\n",
    "    details+=\"\\nFeature extraction + training time: %0.3fs\" % train_time\n",
    "    \n",
    "    t0 = time()\n",
    "    \n",
    "#     pred = baseline.predict(x_test)\n",
    "    texts_for_keras_tokenizer = list([' '.join(tokenizer.tokenize(text)) for text in x_test]) \n",
    "    x_test = keras_tokenizer.texts_to_matrix(texts_for_keras_tokenizer, mode='binary')\n",
    "\n",
    "    keras_pred = model.predict(x_test)\n",
    "\n",
    "    actual_pred = list([np.argmax(values) for values in keras_pred])\n",
    "\n",
    "    test_time = time() - t0\n",
    "    details+=\"\\nTest time:  %0.3fs\" % test_time\n",
    "\n",
    "    exact_accuracy = metrics.accuracy_score(y_test, actual_pred)\n",
    "    details+=\"\\n\\nAccuracy:   %0.3f\" % exact_accuracy\n",
    "\n",
    "    details+='\\nMicro-averaged metrics: '\n",
    "\n",
    "    precision_micro = metrics.precision_score(y_test, actual_pred, average='micro')\n",
    "    details+=\"\\nPrecision:   %0.3f\" % precision_micro\n",
    "\n",
    "    recall_micro = metrics.recall_score(y_test, actual_pred, average='micro')\n",
    "    details+=\"\\nRecall:   %0.3f\" % recall_micro\n",
    "\n",
    "    f_measure_micro = metrics.f1_score(y_test, actual_pred, average='micro')                              \n",
    "    details+=\"\\nF_measure:   %0.3f\" % f_measure_micro\n",
    "\n",
    "    details+='\\nMacro-averaged metrics: '\n",
    "\n",
    "    precision_macro = metrics.precision_score(y_test, actual_pred, average='macro')\n",
    "    details+=\"\\nPrecision:   %0.3f\" % precision_macro\n",
    "\n",
    "    recall_macro = metrics.recall_score(y_test, actual_pred, average='macro')\n",
    "    details+=\"\\nRecall:   %0.3f\" % recall_macro\n",
    "\n",
    "    f_measure_macro = metrics.f1_score(y_test, actual_pred, average='macro')                              \n",
    "    details+=\"\\nF_measure:   %0.3f\" % f_measure_macro\n",
    "\n",
    "    details+='\\nWeighted-average metrics: '\n",
    "\n",
    "    precision_weighted = metrics.precision_score(y_test, actual_pred, average='weighted')\n",
    "    details+=\"\\nPrecision:   %0.3f\" % precision_weighted\n",
    "\n",
    "    recall_weighted = metrics.recall_score(y_test, actual_pred, average='weighted')\n",
    "    details+=\"\\nRecall:   %0.3f\" % recall_weighted\n",
    "\n",
    "    f_measure_weighted = metrics.f1_score(y_test, actual_pred, average='weighted')                              \n",
    "    details+=\"\\nF_measure:   %0.3f\" % f_measure_weighted\n",
    "        \n",
    "        \n",
    "    dl_exact_accuracies.append((exact_accuracy,details))\n",
    "    dl_precisions.append((max(precision_micro,precision_macro,precision_weighted),details))    \n",
    "    dl_recalls.append((max(recall_micro,recall_macro,recall_weighted),details))\n",
    "    dl_f_measures.append((max(f_measure_micro,f_measure_macro,f_measure_weighted),details))\n",
    "    \n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Top 10 accuracies: --------\n",
      "\n",
      "\n",
      "Preprocessing parameters:\n",
      "\n",
      "lower : True\n",
      "stemming : False\n",
      "remove stop words : True\n",
      "remove urls : True\n",
      "remove punctuation : False\n",
      "remove hashtags : none\n",
      "remove ats : none\n",
      "Feature extraction + training time: 183.247s\n",
      "Test time:  1.556s\n",
      "\n",
      "Accuracy:   0.667\n",
      "Micro-averaged metrics: \n",
      "Precision:   0.667\n",
      "Recall:   0.667\n",
      "F_measure:   0.667\n",
      "Macro-averaged metrics: \n",
      "Precision:   0.670\n",
      "Recall:   0.673\n",
      "F_measure:   0.671\n",
      "Weighted-average metrics: \n",
      "Precision:   0.667\n",
      "Recall:   0.667\n",
      "F_measure:   0.667\n",
      "\n",
      "\n",
      "Preprocessing parameters:\n",
      "\n",
      "lower : True\n",
      "stemming : True\n",
      "remove stop words : False\n",
      "remove urls : True\n",
      "remove punctuation : True\n",
      "remove hashtags : none\n",
      "remove ats : entire_expression\n",
      "Feature extraction + training time: 182.408s\n",
      "Test time:  1.965s\n",
      "\n",
      "Accuracy:   0.667\n",
      "Micro-averaged metrics: \n",
      "Precision:   0.667\n",
      "Recall:   0.667\n",
      "F_measure:   0.667\n",
      "Macro-averaged metrics: \n",
      "Precision:   0.659\n",
      "Recall:   0.678\n",
      "F_measure:   0.665\n",
      "Weighted-average metrics: \n",
      "Precision:   0.662\n",
      "Recall:   0.667\n",
      "F_measure:   0.662\n",
      "\n",
      "\n",
      "Preprocessing parameters:\n",
      "\n",
      "lower : True\n",
      "stemming : True\n",
      "remove stop words : False\n",
      "remove urls : False\n",
      "remove punctuation : False\n",
      "remove hashtags : none\n",
      "remove ats : none\n",
      "Feature extraction + training time: 182.809s\n",
      "Test time:  1.772s\n",
      "\n",
      "Accuracy:   0.669\n",
      "Micro-averaged metrics: \n",
      "Precision:   0.669\n",
      "Recall:   0.669\n",
      "F_measure:   0.669\n",
      "Macro-averaged metrics: \n",
      "Precision:   0.671\n",
      "Recall:   0.667\n",
      "F_measure:   0.669\n",
      "Weighted-average metrics: \n",
      "Precision:   0.666\n",
      "Recall:   0.669\n",
      "F_measure:   0.667\n",
      "\n",
      "\n",
      "Preprocessing parameters:\n",
      "\n",
      "lower : True\n",
      "stemming : True\n",
      "remove stop words : False\n",
      "remove urls : False\n",
      "remove punctuation : False\n",
      "remove hashtags : only_symbol\n",
      "remove ats : none\n",
      "Feature extraction + training time: 181.888s\n",
      "Test time:  1.732s\n",
      "\n",
      "Accuracy:   0.670\n",
      "Micro-averaged metrics: \n",
      "Precision:   0.670\n",
      "Recall:   0.670\n",
      "F_measure:   0.670\n",
      "Macro-averaged metrics: \n",
      "Precision:   0.675\n",
      "Recall:   0.679\n",
      "F_measure:   0.676\n",
      "Weighted-average metrics: \n",
      "Precision:   0.667\n",
      "Recall:   0.670\n",
      "F_measure:   0.669\n",
      "\n",
      "\n",
      "Preprocessing parameters:\n",
      "\n",
      "lower : True\n",
      "stemming : True\n",
      "remove stop words : False\n",
      "remove urls : False\n",
      "remove punctuation : False\n",
      "remove hashtags : only_symbol\n",
      "remove ats : entire_expression\n",
      "Feature extraction + training time: 186.525s\n",
      "Test time:  1.898s\n",
      "\n",
      "Accuracy:   0.670\n",
      "Micro-averaged metrics: \n",
      "Precision:   0.670\n",
      "Recall:   0.670\n",
      "F_measure:   0.670\n",
      "Macro-averaged metrics: \n",
      "Precision:   0.672\n",
      "Recall:   0.677\n",
      "F_measure:   0.674\n",
      "Weighted-average metrics: \n",
      "Precision:   0.667\n",
      "Recall:   0.670\n",
      "F_measure:   0.668\n",
      "\n",
      "\n",
      "Preprocessing parameters:\n",
      "\n",
      "lower : False\n",
      "stemming : True\n",
      "remove stop words : False\n",
      "remove urls : False\n",
      "remove punctuation : True\n",
      "remove hashtags : none\n",
      "remove ats : entire_expression\n",
      "Feature extraction + training time: 178.148s\n",
      "Test time:  0.922s\n",
      "\n",
      "Accuracy:   0.671\n",
      "Micro-averaged metrics: \n",
      "Precision:   0.671\n",
      "Recall:   0.671\n",
      "F_measure:   0.671\n",
      "Macro-averaged metrics: \n",
      "Precision:   0.669\n",
      "Recall:   0.674\n",
      "F_measure:   0.669\n",
      "Weighted-average metrics: \n",
      "Precision:   0.665\n",
      "Recall:   0.671\n",
      "F_measure:   0.665\n",
      "\n",
      "\n",
      "Preprocessing parameters:\n",
      "\n",
      "lower : True\n",
      "stemming : True\n",
      "remove stop words : False\n",
      "remove urls : False\n",
      "remove punctuation : True\n",
      "remove hashtags : only_symbol\n",
      "remove ats : none\n",
      "Feature extraction + training time: 181.744s\n",
      "Test time:  1.786s\n",
      "\n",
      "Accuracy:   0.673\n",
      "Micro-averaged metrics: \n",
      "Precision:   0.673\n",
      "Recall:   0.673\n",
      "F_measure:   0.673\n",
      "Macro-averaged metrics: \n",
      "Precision:   0.674\n",
      "Recall:   0.669\n",
      "F_measure:   0.670\n",
      "Weighted-average metrics: \n",
      "Precision:   0.668\n",
      "Recall:   0.673\n",
      "F_measure:   0.669\n",
      "\n",
      "\n",
      "Preprocessing parameters:\n",
      "\n",
      "lower : True\n",
      "stemming : True\n",
      "remove stop words : False\n",
      "remove urls : True\n",
      "remove punctuation : False\n",
      "remove hashtags : only_symbol\n",
      "remove ats : none\n",
      "Feature extraction + training time: 183.237s\n",
      "Test time:  2.046s\n",
      "\n",
      "Accuracy:   0.673\n",
      "Micro-averaged metrics: \n",
      "Precision:   0.673\n",
      "Recall:   0.673\n",
      "F_measure:   0.673\n",
      "Macro-averaged metrics: \n",
      "Precision:   0.676\n",
      "Recall:   0.681\n",
      "F_measure:   0.678\n",
      "Weighted-average metrics: \n",
      "Precision:   0.671\n",
      "Recall:   0.673\n",
      "F_measure:   0.672\n",
      "\n",
      "\n",
      "Preprocessing parameters:\n",
      "\n",
      "lower : False\n",
      "stemming : True\n",
      "remove stop words : False\n",
      "remove urls : False\n",
      "remove punctuation : False\n",
      "remove hashtags : none\n",
      "remove ats : entire_expression\n",
      "Feature extraction + training time: 181.197s\n",
      "Test time:  0.978s\n",
      "\n",
      "Accuracy:   0.674\n",
      "Micro-averaged metrics: \n",
      "Precision:   0.674\n",
      "Recall:   0.674\n",
      "F_measure:   0.674\n",
      "Macro-averaged metrics: \n",
      "Precision:   0.680\n",
      "Recall:   0.677\n",
      "F_measure:   0.679\n",
      "Weighted-average metrics: \n",
      "Precision:   0.677\n",
      "Recall:   0.674\n",
      "F_measure:   0.676\n",
      "\n",
      "\n",
      "Preprocessing parameters:\n",
      "\n",
      "lower : False\n",
      "stemming : True\n",
      "remove stop words : True\n",
      "remove urls : True\n",
      "remove punctuation : False\n",
      "remove hashtags : none\n",
      "remove ats : none\n",
      "Feature extraction + training time: 180.201s\n",
      "Test time:  1.149s\n",
      "\n",
      "Accuracy:   0.674\n",
      "Micro-averaged metrics: \n",
      "Precision:   0.674\n",
      "Recall:   0.674\n",
      "F_measure:   0.674\n",
      "Macro-averaged metrics: \n",
      "Precision:   0.672\n",
      "Recall:   0.688\n",
      "F_measure:   0.679\n",
      "Weighted-average metrics: \n",
      "Precision:   0.673\n",
      "Recall:   0.674\n",
      "F_measure:   0.673\n",
      "--------Top 10 precisions: --------\n",
      "\n",
      "\n",
      "Preprocessing parameters:\n",
      "\n",
      "lower : False\n",
      "stemming : True\n",
      "remove stop words : False\n",
      "remove urls : False\n",
      "remove punctuation : False\n",
      "remove hashtags : none\n",
      "remove ats : none\n",
      "Feature extraction + training time: 178.767s\n",
      "Test time:  0.859s\n",
      "\n",
      "Accuracy:   0.667\n",
      "Micro-averaged metrics: \n",
      "Precision:   0.667\n",
      "Recall:   0.667\n",
      "F_measure:   0.667\n",
      "Macro-averaged metrics: \n",
      "Precision:   0.656\n",
      "Recall:   0.690\n",
      "F_measure:   0.666\n",
      "Weighted-average metrics: \n",
      "Precision:   0.672\n",
      "Recall:   0.667\n",
      "F_measure:   0.665\n",
      "\n",
      "\n",
      "Preprocessing parameters:\n",
      "\n",
      "lower : False\n",
      "stemming : False\n",
      "remove stop words : True\n",
      "remove urls : False\n",
      "remove punctuation : False\n",
      "remove hashtags : none\n",
      "remove ats : entire_expression\n",
      "Feature extraction + training time: 173.360s\n",
      "Test time:  0.631s\n",
      "\n",
      "Accuracy:   0.658\n",
      "Micro-averaged metrics: \n",
      "Precision:   0.658\n",
      "Recall:   0.658\n",
      "F_measure:   0.658\n",
      "Macro-averaged metrics: \n",
      "Precision:   0.673\n",
      "Recall:   0.665\n",
      "F_measure:   0.668\n",
      "Weighted-average metrics: \n",
      "Precision:   0.667\n",
      "Recall:   0.658\n",
      "F_measure:   0.661\n",
      "\n",
      "\n",
      "Preprocessing parameters:\n",
      "\n",
      "lower : False\n",
      "stemming : True\n",
      "remove stop words : False\n",
      "remove urls : False\n",
      "remove punctuation : False\n",
      "remove hashtags : only_symbol\n",
      "remove ats : none\n",
      "Feature extraction + training time: 183.792s\n",
      "Test time:  0.937s\n",
      "\n",
      "Accuracy:   0.649\n",
      "Micro-averaged metrics: \n",
      "Precision:   0.649\n",
      "Recall:   0.649\n",
      "F_measure:   0.649\n",
      "Macro-averaged metrics: \n",
      "Precision:   0.673\n",
      "Recall:   0.659\n",
      "F_measure:   0.661\n",
      "Weighted-average metrics: \n",
      "Precision:   0.668\n",
      "Recall:   0.649\n",
      "F_measure:   0.654\n",
      "\n",
      "\n",
      "Preprocessing parameters:\n",
      "\n",
      "lower : True\n",
      "stemming : True\n",
      "remove stop words : False\n",
      "remove urls : False\n",
      "remove punctuation : True\n",
      "remove hashtags : only_symbol\n",
      "remove ats : none\n",
      "Feature extraction + training time: 181.744s\n",
      "Test time:  1.786s\n",
      "\n",
      "Accuracy:   0.673\n",
      "Micro-averaged metrics: \n",
      "Precision:   0.673\n",
      "Recall:   0.673\n",
      "F_measure:   0.673\n",
      "Macro-averaged metrics: \n",
      "Precision:   0.674\n",
      "Recall:   0.669\n",
      "F_measure:   0.670\n",
      "Weighted-average metrics: \n",
      "Precision:   0.668\n",
      "Recall:   0.673\n",
      "F_measure:   0.669\n",
      "\n",
      "\n",
      "Preprocessing parameters:\n",
      "\n",
      "lower : False\n",
      "stemming : True\n",
      "remove stop words : True\n",
      "remove urls : True\n",
      "remove punctuation : False\n",
      "remove hashtags : none\n",
      "remove ats : none\n",
      "Feature extraction + training time: 180.201s\n",
      "Test time:  1.149s\n",
      "\n",
      "Accuracy:   0.674\n",
      "Micro-averaged metrics: \n",
      "Precision:   0.674\n",
      "Recall:   0.674\n",
      "F_measure:   0.674\n",
      "Macro-averaged metrics: \n",
      "Precision:   0.672\n",
      "Recall:   0.688\n",
      "F_measure:   0.679\n",
      "Weighted-average metrics: \n",
      "Precision:   0.673\n",
      "Recall:   0.674\n",
      "F_measure:   0.673\n",
      "\n",
      "\n",
      "Preprocessing parameters:\n",
      "\n",
      "lower : True\n",
      "stemming : True\n",
      "remove stop words : False\n",
      "remove urls : False\n",
      "remove punctuation : False\n",
      "remove hashtags : none\n",
      "remove ats : entire_expression\n",
      "Feature extraction + training time: 182.955s\n",
      "Test time:  1.847s\n",
      "\n",
      "Accuracy:   0.664\n",
      "Micro-averaged metrics: \n",
      "Precision:   0.664\n",
      "Recall:   0.664\n",
      "F_measure:   0.664\n",
      "Macro-averaged metrics: \n",
      "Precision:   0.674\n",
      "Recall:   0.681\n",
      "F_measure:   0.676\n",
      "Weighted-average metrics: \n",
      "Precision:   0.674\n",
      "Recall:   0.664\n",
      "F_measure:   0.667\n",
      "\n",
      "\n",
      "Preprocessing parameters:\n",
      "\n",
      "lower : True\n",
      "stemming : True\n",
      "remove stop words : False\n",
      "remove urls : False\n",
      "remove punctuation : False\n",
      "remove hashtags : only_symbol\n",
      "remove ats : none\n",
      "Feature extraction + training time: 181.888s\n",
      "Test time:  1.732s\n",
      "\n",
      "Accuracy:   0.670\n",
      "Micro-averaged metrics: \n",
      "Precision:   0.670\n",
      "Recall:   0.670\n",
      "F_measure:   0.670\n",
      "Macro-averaged metrics: \n",
      "Precision:   0.675\n",
      "Recall:   0.679\n",
      "F_measure:   0.676\n",
      "Weighted-average metrics: \n",
      "Precision:   0.667\n",
      "Recall:   0.670\n",
      "F_measure:   0.669\n",
      "\n",
      "\n",
      "Preprocessing parameters:\n",
      "\n",
      "lower : True\n",
      "stemming : True\n",
      "remove stop words : False\n",
      "remove urls : True\n",
      "remove punctuation : False\n",
      "remove hashtags : only_symbol\n",
      "remove ats : none\n",
      "Feature extraction + training time: 183.237s\n",
      "Test time:  2.046s\n",
      "\n",
      "Accuracy:   0.673\n",
      "Micro-averaged metrics: \n",
      "Precision:   0.673\n",
      "Recall:   0.673\n",
      "F_measure:   0.673\n",
      "Macro-averaged metrics: \n",
      "Precision:   0.676\n",
      "Recall:   0.681\n",
      "F_measure:   0.678\n",
      "Weighted-average metrics: \n",
      "Precision:   0.671\n",
      "Recall:   0.673\n",
      "F_measure:   0.672\n",
      "\n",
      "\n",
      "Preprocessing parameters:\n",
      "\n",
      "lower : True\n",
      "stemming : False\n",
      "remove stop words : False\n",
      "remove urls : True\n",
      "remove punctuation : False\n",
      "remove hashtags : only_symbol\n",
      "remove ats : none\n",
      "Feature extraction + training time: 178.924s\n",
      "Test time:  1.406s\n",
      "\n",
      "Accuracy:   0.667\n",
      "Micro-averaged metrics: \n",
      "Precision:   0.667\n",
      "Recall:   0.667\n",
      "F_measure:   0.667\n",
      "Macro-averaged metrics: \n",
      "Precision:   0.676\n",
      "Recall:   0.675\n",
      "F_measure:   0.676\n",
      "Weighted-average metrics: \n",
      "Precision:   0.668\n",
      "Recall:   0.667\n",
      "F_measure:   0.667\n",
      "\n",
      "\n",
      "Preprocessing parameters:\n",
      "\n",
      "lower : False\n",
      "stemming : True\n",
      "remove stop words : False\n",
      "remove urls : False\n",
      "remove punctuation : False\n",
      "remove hashtags : none\n",
      "remove ats : entire_expression\n",
      "Feature extraction + training time: 181.197s\n",
      "Test time:  0.978s\n",
      "\n",
      "Accuracy:   0.674\n",
      "Micro-averaged metrics: \n",
      "Precision:   0.674\n",
      "Recall:   0.674\n",
      "F_measure:   0.674\n",
      "Macro-averaged metrics: \n",
      "Precision:   0.680\n",
      "Recall:   0.677\n",
      "F_measure:   0.679\n",
      "Weighted-average metrics: \n",
      "Precision:   0.677\n",
      "Recall:   0.674\n",
      "F_measure:   0.676\n",
      "--------Top 10 recalls: --------\n",
      "\n",
      "\n",
      "Preprocessing parameters:\n",
      "\n",
      "lower : True\n",
      "stemming : False\n",
      "remove stop words : False\n",
      "remove urls : False\n",
      "remove punctuation : False\n",
      "remove hashtags : only_symbol\n",
      "remove ats : none\n",
      "Feature extraction + training time: 176.466s\n",
      "Test time:  1.303s\n",
      "\n",
      "Accuracy:   0.665\n",
      "Micro-averaged metrics: \n",
      "Precision:   0.665\n",
      "Recall:   0.665\n",
      "F_measure:   0.665\n",
      "Macro-averaged metrics: \n",
      "Precision:   0.669\n",
      "Recall:   0.680\n",
      "F_measure:   0.674\n",
      "Weighted-average metrics: \n",
      "Precision:   0.668\n",
      "Recall:   0.665\n",
      "F_measure:   0.666\n",
      "\n",
      "\n",
      "Preprocessing parameters:\n",
      "\n",
      "lower : False\n",
      "stemming : False\n",
      "remove stop words : False\n",
      "remove urls : False\n",
      "remove punctuation : False\n",
      "remove hashtags : only_symbol\n",
      "remove ats : entire_expression\n",
      "Feature extraction + training time: 174.374s\n",
      "Test time:  0.528s\n",
      "\n",
      "Accuracy:   0.665\n",
      "Micro-averaged metrics: \n",
      "Precision:   0.665\n",
      "Recall:   0.665\n",
      "F_measure:   0.665\n",
      "Macro-averaged metrics: \n",
      "Precision:   0.672\n",
      "Recall:   0.681\n",
      "F_measure:   0.675\n",
      "Weighted-average metrics: \n",
      "Precision:   0.670\n",
      "Recall:   0.665\n",
      "F_measure:   0.666\n",
      "\n",
      "\n",
      "Preprocessing parameters:\n",
      "\n",
      "lower : True\n",
      "stemming : True\n",
      "remove stop words : False\n",
      "remove urls : False\n",
      "remove punctuation : False\n",
      "remove hashtags : none\n",
      "remove ats : entire_expression\n",
      "Feature extraction + training time: 182.955s\n",
      "Test time:  1.847s\n",
      "\n",
      "Accuracy:   0.664\n",
      "Micro-averaged metrics: \n",
      "Precision:   0.664\n",
      "Recall:   0.664\n",
      "F_measure:   0.664\n",
      "Macro-averaged metrics: \n",
      "Precision:   0.674\n",
      "Recall:   0.681\n",
      "F_measure:   0.676\n",
      "Weighted-average metrics: \n",
      "Precision:   0.674\n",
      "Recall:   0.664\n",
      "F_measure:   0.667\n",
      "\n",
      "\n",
      "Preprocessing parameters:\n",
      "\n",
      "lower : True\n",
      "stemming : False\n",
      "remove stop words : False\n",
      "remove urls : False\n",
      "remove punctuation : False\n",
      "remove hashtags : none\n",
      "remove ats : none\n",
      "Feature extraction + training time: 178.381s\n",
      "Test time:  1.292s\n",
      "\n",
      "Accuracy:   0.655\n",
      "Micro-averaged metrics: \n",
      "Precision:   0.655\n",
      "Recall:   0.655\n",
      "F_measure:   0.655\n",
      "Macro-averaged metrics: \n",
      "Precision:   0.656\n",
      "Recall:   0.681\n",
      "F_measure:   0.664\n",
      "Weighted-average metrics: \n",
      "Precision:   0.665\n",
      "Recall:   0.655\n",
      "F_measure:   0.655\n",
      "\n",
      "\n",
      "Preprocessing parameters:\n",
      "\n",
      "lower : False\n",
      "stemming : True\n",
      "remove stop words : True\n",
      "remove urls : False\n",
      "remove punctuation : False\n",
      "remove hashtags : none\n",
      "remove ats : entire_expression\n",
      "Feature extraction + training time: 181.788s\n",
      "Test time:  1.133s\n",
      "\n",
      "Accuracy:   0.667\n",
      "Micro-averaged metrics: \n",
      "Precision:   0.667\n",
      "Recall:   0.667\n",
      "F_measure:   0.667\n",
      "Macro-averaged metrics: \n",
      "Precision:   0.667\n",
      "Recall:   0.681\n",
      "F_measure:   0.673\n",
      "Weighted-average metrics: \n",
      "Precision:   0.670\n",
      "Recall:   0.667\n",
      "F_measure:   0.668\n",
      "\n",
      "\n",
      "Preprocessing parameters:\n",
      "\n",
      "lower : False\n",
      "stemming : True\n",
      "remove stop words : True\n",
      "remove urls : True\n",
      "remove punctuation : False\n",
      "remove hashtags : only_symbol\n",
      "remove ats : none\n",
      "Feature extraction + training time: 181.465s\n",
      "Test time:  1.165s\n",
      "\n",
      "Accuracy:   0.667\n",
      "Micro-averaged metrics: \n",
      "Precision:   0.667\n",
      "Recall:   0.667\n",
      "F_measure:   0.667\n",
      "Macro-averaged metrics: \n",
      "Precision:   0.665\n",
      "Recall:   0.681\n",
      "F_measure:   0.672\n",
      "Weighted-average metrics: \n",
      "Precision:   0.666\n",
      "Recall:   0.667\n",
      "F_measure:   0.666\n",
      "\n",
      "\n",
      "Preprocessing parameters:\n",
      "\n",
      "lower : True\n",
      "stemming : True\n",
      "remove stop words : False\n",
      "remove urls : True\n",
      "remove punctuation : False\n",
      "remove hashtags : only_symbol\n",
      "remove ats : none\n",
      "Feature extraction + training time: 183.237s\n",
      "Test time:  2.046s\n",
      "\n",
      "Accuracy:   0.673\n",
      "Micro-averaged metrics: \n",
      "Precision:   0.673\n",
      "Recall:   0.673\n",
      "F_measure:   0.673\n",
      "Macro-averaged metrics: \n",
      "Precision:   0.676\n",
      "Recall:   0.681\n",
      "F_measure:   0.678\n",
      "Weighted-average metrics: \n",
      "Precision:   0.671\n",
      "Recall:   0.673\n",
      "F_measure:   0.672\n",
      "\n",
      "\n",
      "Preprocessing parameters:\n",
      "\n",
      "lower : True\n",
      "stemming : False\n",
      "remove stop words : False\n",
      "remove urls : True\n",
      "remove punctuation : True\n",
      "remove hashtags : none\n",
      "remove ats : none\n",
      "Feature extraction + training time: 183.969s\n",
      "Test time:  1.397s\n",
      "\n",
      "Accuracy:   0.667\n",
      "Micro-averaged metrics: \n",
      "Precision:   0.667\n",
      "Recall:   0.667\n",
      "F_measure:   0.667\n",
      "Macro-averaged metrics: \n",
      "Precision:   0.663\n",
      "Recall:   0.682\n",
      "F_measure:   0.671\n",
      "Weighted-average metrics: \n",
      "Precision:   0.667\n",
      "Recall:   0.667\n",
      "F_measure:   0.666\n",
      "\n",
      "\n",
      "Preprocessing parameters:\n",
      "\n",
      "lower : False\n",
      "stemming : True\n",
      "remove stop words : True\n",
      "remove urls : True\n",
      "remove punctuation : False\n",
      "remove hashtags : none\n",
      "remove ats : none\n",
      "Feature extraction + training time: 180.201s\n",
      "Test time:  1.149s\n",
      "\n",
      "Accuracy:   0.674\n",
      "Micro-averaged metrics: \n",
      "Precision:   0.674\n",
      "Recall:   0.674\n",
      "F_measure:   0.674\n",
      "Macro-averaged metrics: \n",
      "Precision:   0.672\n",
      "Recall:   0.688\n",
      "F_measure:   0.679\n",
      "Weighted-average metrics: \n",
      "Precision:   0.673\n",
      "Recall:   0.674\n",
      "F_measure:   0.673\n",
      "\n",
      "\n",
      "Preprocessing parameters:\n",
      "\n",
      "lower : False\n",
      "stemming : True\n",
      "remove stop words : False\n",
      "remove urls : False\n",
      "remove punctuation : False\n",
      "remove hashtags : none\n",
      "remove ats : none\n",
      "Feature extraction + training time: 178.767s\n",
      "Test time:  0.859s\n",
      "\n",
      "Accuracy:   0.667\n",
      "Micro-averaged metrics: \n",
      "Precision:   0.667\n",
      "Recall:   0.667\n",
      "F_measure:   0.667\n",
      "Macro-averaged metrics: \n",
      "Precision:   0.656\n",
      "Recall:   0.690\n",
      "F_measure:   0.666\n",
      "Weighted-average metrics: \n",
      "Precision:   0.672\n",
      "Recall:   0.667\n",
      "F_measure:   0.665\n",
      "--------Top 10 f-measures: --------\n",
      "\n",
      "\n",
      "Preprocessing parameters:\n",
      "\n",
      "lower : False\n",
      "stemming : True\n",
      "remove stop words : True\n",
      "remove urls : False\n",
      "remove punctuation : False\n",
      "remove hashtags : none\n",
      "remove ats : entire_expression\n",
      "Feature extraction + training time: 181.788s\n",
      "Test time:  1.133s\n",
      "\n",
      "Accuracy:   0.667\n",
      "Micro-averaged metrics: \n",
      "Precision:   0.667\n",
      "Recall:   0.667\n",
      "F_measure:   0.667\n",
      "Macro-averaged metrics: \n",
      "Precision:   0.667\n",
      "Recall:   0.681\n",
      "F_measure:   0.673\n",
      "Weighted-average metrics: \n",
      "Precision:   0.670\n",
      "Recall:   0.667\n",
      "F_measure:   0.668\n",
      "\n",
      "\n",
      "Preprocessing parameters:\n",
      "\n",
      "lower : True\n",
      "stemming : False\n",
      "remove stop words : False\n",
      "remove urls : False\n",
      "remove punctuation : False\n",
      "remove hashtags : only_symbol\n",
      "remove ats : none\n",
      "Feature extraction + training time: 176.466s\n",
      "Test time:  1.303s\n",
      "\n",
      "Accuracy:   0.665\n",
      "Micro-averaged metrics: \n",
      "Precision:   0.665\n",
      "Recall:   0.665\n",
      "F_measure:   0.665\n",
      "Macro-averaged metrics: \n",
      "Precision:   0.669\n",
      "Recall:   0.680\n",
      "F_measure:   0.674\n",
      "Weighted-average metrics: \n",
      "Precision:   0.668\n",
      "Recall:   0.665\n",
      "F_measure:   0.666\n",
      "\n",
      "\n",
      "Preprocessing parameters:\n",
      "\n",
      "lower : True\n",
      "stemming : True\n",
      "remove stop words : False\n",
      "remove urls : False\n",
      "remove punctuation : False\n",
      "remove hashtags : only_symbol\n",
      "remove ats : entire_expression\n",
      "Feature extraction + training time: 186.525s\n",
      "Test time:  1.898s\n",
      "\n",
      "Accuracy:   0.670\n",
      "Micro-averaged metrics: \n",
      "Precision:   0.670\n",
      "Recall:   0.670\n",
      "F_measure:   0.670\n",
      "Macro-averaged metrics: \n",
      "Precision:   0.672\n",
      "Recall:   0.677\n",
      "F_measure:   0.674\n",
      "Weighted-average metrics: \n",
      "Precision:   0.667\n",
      "Recall:   0.670\n",
      "F_measure:   0.668\n",
      "\n",
      "\n",
      "Preprocessing parameters:\n",
      "\n",
      "lower : False\n",
      "stemming : False\n",
      "remove stop words : False\n",
      "remove urls : False\n",
      "remove punctuation : False\n",
      "remove hashtags : only_symbol\n",
      "remove ats : entire_expression\n",
      "Feature extraction + training time: 174.374s\n",
      "Test time:  0.528s\n",
      "\n",
      "Accuracy:   0.665\n",
      "Micro-averaged metrics: \n",
      "Precision:   0.665\n",
      "Recall:   0.665\n",
      "F_measure:   0.665\n",
      "Macro-averaged metrics: \n",
      "Precision:   0.672\n",
      "Recall:   0.681\n",
      "F_measure:   0.675\n",
      "Weighted-average metrics: \n",
      "Precision:   0.670\n",
      "Recall:   0.665\n",
      "F_measure:   0.666\n",
      "\n",
      "\n",
      "Preprocessing parameters:\n",
      "\n",
      "lower : True\n",
      "stemming : False\n",
      "remove stop words : False\n",
      "remove urls : True\n",
      "remove punctuation : False\n",
      "remove hashtags : only_symbol\n",
      "remove ats : none\n",
      "Feature extraction + training time: 178.924s\n",
      "Test time:  1.406s\n",
      "\n",
      "Accuracy:   0.667\n",
      "Micro-averaged metrics: \n",
      "Precision:   0.667\n",
      "Recall:   0.667\n",
      "F_measure:   0.667\n",
      "Macro-averaged metrics: \n",
      "Precision:   0.676\n",
      "Recall:   0.675\n",
      "F_measure:   0.676\n",
      "Weighted-average metrics: \n",
      "Precision:   0.668\n",
      "Recall:   0.667\n",
      "F_measure:   0.667\n",
      "\n",
      "\n",
      "Preprocessing parameters:\n",
      "\n",
      "lower : True\n",
      "stemming : True\n",
      "remove stop words : False\n",
      "remove urls : False\n",
      "remove punctuation : False\n",
      "remove hashtags : none\n",
      "remove ats : entire_expression\n",
      "Feature extraction + training time: 182.955s\n",
      "Test time:  1.847s\n",
      "\n",
      "Accuracy:   0.664\n",
      "Micro-averaged metrics: \n",
      "Precision:   0.664\n",
      "Recall:   0.664\n",
      "F_measure:   0.664\n",
      "Macro-averaged metrics: \n",
      "Precision:   0.674\n",
      "Recall:   0.681\n",
      "F_measure:   0.676\n",
      "Weighted-average metrics: \n",
      "Precision:   0.674\n",
      "Recall:   0.664\n",
      "F_measure:   0.667\n",
      "\n",
      "\n",
      "Preprocessing parameters:\n",
      "\n",
      "lower : True\n",
      "stemming : True\n",
      "remove stop words : False\n",
      "remove urls : False\n",
      "remove punctuation : False\n",
      "remove hashtags : only_symbol\n",
      "remove ats : none\n",
      "Feature extraction + training time: 181.888s\n",
      "Test time:  1.732s\n",
      "\n",
      "Accuracy:   0.670\n",
      "Micro-averaged metrics: \n",
      "Precision:   0.670\n",
      "Recall:   0.670\n",
      "F_measure:   0.670\n",
      "Macro-averaged metrics: \n",
      "Precision:   0.675\n",
      "Recall:   0.679\n",
      "F_measure:   0.676\n",
      "Weighted-average metrics: \n",
      "Precision:   0.667\n",
      "Recall:   0.670\n",
      "F_measure:   0.669\n",
      "\n",
      "\n",
      "Preprocessing parameters:\n",
      "\n",
      "lower : True\n",
      "stemming : True\n",
      "remove stop words : False\n",
      "remove urls : True\n",
      "remove punctuation : False\n",
      "remove hashtags : only_symbol\n",
      "remove ats : none\n",
      "Feature extraction + training time: 183.237s\n",
      "Test time:  2.046s\n",
      "\n",
      "Accuracy:   0.673\n",
      "Micro-averaged metrics: \n",
      "Precision:   0.673\n",
      "Recall:   0.673\n",
      "F_measure:   0.673\n",
      "Macro-averaged metrics: \n",
      "Precision:   0.676\n",
      "Recall:   0.681\n",
      "F_measure:   0.678\n",
      "Weighted-average metrics: \n",
      "Precision:   0.671\n",
      "Recall:   0.673\n",
      "F_measure:   0.672\n",
      "\n",
      "\n",
      "Preprocessing parameters:\n",
      "\n",
      "lower : False\n",
      "stemming : True\n",
      "remove stop words : False\n",
      "remove urls : False\n",
      "remove punctuation : False\n",
      "remove hashtags : none\n",
      "remove ats : entire_expression\n",
      "Feature extraction + training time: 181.197s\n",
      "Test time:  0.978s\n",
      "\n",
      "Accuracy:   0.674\n",
      "Micro-averaged metrics: \n",
      "Precision:   0.674\n",
      "Recall:   0.674\n",
      "F_measure:   0.674\n",
      "Macro-averaged metrics: \n",
      "Precision:   0.680\n",
      "Recall:   0.677\n",
      "F_measure:   0.679\n",
      "Weighted-average metrics: \n",
      "Precision:   0.677\n",
      "Recall:   0.674\n",
      "F_measure:   0.676\n",
      "\n",
      "\n",
      "Preprocessing parameters:\n",
      "\n",
      "lower : False\n",
      "stemming : True\n",
      "remove stop words : True\n",
      "remove urls : True\n",
      "remove punctuation : False\n",
      "remove hashtags : none\n",
      "remove ats : none\n",
      "Feature extraction + training time: 180.201s\n",
      "Test time:  1.149s\n",
      "\n",
      "Accuracy:   0.674\n",
      "Micro-averaged metrics: \n",
      "Precision:   0.674\n",
      "Recall:   0.674\n",
      "F_measure:   0.674\n",
      "Macro-averaged metrics: \n",
      "Precision:   0.672\n",
      "Recall:   0.688\n",
      "F_measure:   0.679\n",
      "Weighted-average metrics: \n",
      "Precision:   0.673\n",
      "Recall:   0.674\n",
      "F_measure:   0.673\n"
     ]
    }
   ],
   "source": [
    "sorted_accuracies = sorted(dl_exact_accuracies, key=lambda x: x[0])[-10:]\n",
    "sorted_precisions = sorted(dl_precisions, key=lambda x: x[0])[-10:]\n",
    "sorted_recalls = sorted(dl_recalls, key=lambda x: x[0])[-10:]\n",
    "sorted_f_measures = sorted(dl_f_measures, key=lambda x: x[0])[-10:]\n",
    "\n",
    "print('-'*8 + 'Top 10 accuracies: '+'-'*8)\n",
    "for value,details in sorted_accuracies:\n",
    "    print(details)\n",
    "   \n",
    "print('-'*8 + 'Top 10 precisions: '+'-'*8)\n",
    "for value,details in sorted_precisions:\n",
    "    print(details)  \n",
    "\n",
    "print('-'*8 + 'Top 10 recalls: '+'-'*8)\n",
    "for value,details in sorted_recalls:\n",
    "    print(details)   \n",
    "\n",
    "print('-'*8 + 'Top 10 f-measures: '+'-'*8)\n",
    "for value,details in sorted_f_measures:\n",
    "    print(details) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
